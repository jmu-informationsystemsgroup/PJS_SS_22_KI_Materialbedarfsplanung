{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import utlis2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(10,160)\n",
    "cap.set(3,1920) #width\n",
    "cap.set(4,1080) #hight\n",
    "#Skalierungsfaktor sonst wäre das Bild nur 210*297\n",
    "scale = 3\n",
    "wP = 210 *scale\n",
    "hP= 297 *scale\n",
    "\n",
    "#Bild einlesen:\n",
    "img = cv2.imread(\"F:\\\\Projektseminar\\\\Edge Detection\\\\Test.jpg\") #F:/Projektseminar/Baustellenbilder/Wand1_6.jpg\n",
    "i=1\n",
    "if i<2:  #while True: \n",
    "    imgContours , conts = utlis.getContours(img,minArea=10,filter=4, showCanny=False) #Filter 4 weil nur nach 4eckigen Objekten gesucht wird minArea=50000\n",
    "    if len(conts) != 0:\n",
    "        biggest = conts[0][2]\n",
    "        #print(biggest)\n",
    "        imgWarp = utlis.warpImg(img, biggest, wP,hP)\n",
    "        imgContours2, conts2 = utlis.getContours(imgWarp,\n",
    "                                                 minArea=2000, filter=4,\n",
    "                                                 cThr=[50,50],draw = False)\n",
    "        if len(conts) != 0:\n",
    "            for obj in conts2:\n",
    "                cv2.polylines(imgContours2,[obj[2]],True,(0,255,0),2)\n",
    "                nPoints = utlis.reorder(obj[2])\n",
    "                nW = round((utlis.findDis(nPoints[0][0]//scale,nPoints[1][0]//scale)/10),1)\n",
    "                nH = round((utlis.findDis(nPoints[0][0]//scale,nPoints[2][0]//scale)/10),1)\n",
    "                cv2.arrowedLine(imgContours2, (nPoints[0][0][0], nPoints[0][0][1]), (nPoints[1][0][0], nPoints[1][0][1]),\n",
    "                                (255, 0, 255), 3, 8, 0, 0.05)\n",
    "                cv2.arrowedLine(imgContours2, (nPoints[0][0][0], nPoints[0][0][1]), (nPoints[2][0][0], nPoints[2][0][1]),\n",
    "                                (255, 0, 255), 3, 8, 0, 0.05)\n",
    "                x, y, w, h = obj[3]\n",
    "                cv2.putText(imgContours2, '{}cm'.format(nW), (x + 30, y - 10), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1.5,\n",
    "                            (255, 0, 255), 2)\n",
    "                cv2.putText(imgContours2, '{}cm'.format(nH), (x - 70, y + h // 2), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1.5,\n",
    "                            (255, 0, 255), 2)\n",
    "        cv2.imwrite(\"F:\\\\Projektseminar\\\\Edge Detection\\\\Resultat.jpg\", imgContours2)\n",
    "        #cv2.imshow('A4', imgContours2)\n",
    " \n",
    "    #img = cv2.resize(img,(0,0),None,0.5,0.5) #error: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4058: error: (-215:Assertion failed) !dsize.empty() in function 'cv::resize'\n",
    "    #cv2.imshow('Original',img)\n",
    "    cv2.waitKey(1)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bild Warpen:\n",
    "#https://towardsdatascience.com/image-processing-with-python-applying-homography-for-image-warping-84cd87d2108f\n",
    "#Statt der festgelegten Punkte im Bild müssen wir die Eckpunkte im Aruco Sticker benutzen!\n",
    "#Wahrscheinlich besser: https://www.youtube.com/watch?v=dpjhGobnCxU\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Circle\n",
    "from skimage import transform\n",
    "from skimage.io import imread, imshow\n",
    "import cv2\n",
    "\n",
    "img =cv2.imread(\"F:\\\\Projektseminar\\\\Edge Detection\\\\Test.jpg\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
