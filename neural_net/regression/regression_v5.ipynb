{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "vyKYTIBl9gNj"
      },
      "outputs": [],
      "source": [
        "# !pip install keras-buoy\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import date, datetime\n",
        "from random import shuffle\n",
        "\n",
        "import csv\n",
        "from csv import writer\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from keras.utils.layer_utils import count_params\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Dropout, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from keras_buoy.models import ResumableModel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPZzyxuuJ27-",
        "outputId": "09675c5a-d021-43f4-c4ee-cdd54bf4c987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "########################################################################\n",
        "# Hauptverzeichnisse festlegen (Google Colab)\n",
        "########################################################################\n",
        "# Lädt Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "###############################################\n",
        "# Quellpfade zum Einlesen der Bilder und Labels\n",
        "###############################################\n",
        "srcpath_images = \"/content/drive/My Drive/Bilddaten/\"\n",
        "srcpath_label_infos = \"/content/drive/My Drive/Wand_Label_Infos/\"\n",
        "# Wie heißt die CSV Datei in der die Labelinfos gespeichert sind\n",
        "csv_name = \"Wand_Label_Info7.csv\"\n",
        "# Spalte in der CSV Datei in der die Labelinfos über die \n",
        "# Spachtelmasse (putty) gespeichert sind. \n",
        "# Achtung counter beginnt mit 0\n",
        "csv_spalte_labelinfo_putty = 23\n",
        "\n",
        "\n",
        "###############################################\n",
        "# Gibt die Nummer des Trainings an\n",
        "###############################################\n",
        "# Achtung! Nummer des Trainings nicht wiederverwenden\n",
        "numberoftraining = 3\n",
        "\n",
        "\n",
        "###############################################\n",
        "# Gibt den Zielpfad für Infos des Trainings an\n",
        "###############################################\n",
        "destpath_dir = \"/content/drive/My Drive/Training/Training\" + str(numberoftraining) + \"/\"\n",
        "# Gibt die Pfade zum Zwischenspeichern der verwendeten Bilder an\n",
        "# VORSICHT! ORDNER WERDEN BEIM START DES SKRIPTS GELÖSCHT/GELEERT!\n",
        "destpath_train_images = destpath_dir + \"Dataset/Trainingset/\"\n",
        "destpath_val_images = destpath_dir + \"Dataset/Validationset/\"\n",
        "destpath_test_images = destpath_dir + \"Dataset/Testset/\"\n",
        "# Gibt den Pfad zum speichern des trainierten Modells an\n",
        "destpath_modelsave = destpath_dir + \"models/\"\n",
        "# Gibt den Pfad zum Speichern der Modell-Plots an\n",
        "destpath_plotsave = destpath_dir + \"Plot/\"\n",
        "destpath_logsave = destpath_dir + \"Logs/\"\n",
        "\n",
        "\n",
        "##################################################\n",
        "# Gibt den Pfad für die Evaluation an\n",
        "##################################################\n",
        "path_eval = \"/content/drive/My Drive/Training/Evaluation.csv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGW_zc1EK5Kh"
      },
      "outputs": [],
      "source": [
        "###################################################################\n",
        "# Arbeitsverzeichnisse festlegen (Windows)\n",
        "###################################################################\n",
        "# Gibt die Pfade zum Einlesen der Bilder und Labels an\n",
        "srcpath_images = \"C:/Users/DanielWeller/Desktop/Testdaten/\"\n",
        "srcpath_label_infos = \"C:/Users/DanielWeller/Desktop/Wand_Label_Infos/\"\n",
        "srcpath_predict_images = \"C:/Users/DanielWeller/Desktop/Predict/\"\n",
        "\n",
        "\n",
        "# Gibt den Zielpfad an\n",
        "destpath_dir = \"C:/Users/DanielWeller/Desktop/Training1/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Anzahl der Bilder im Verzeichnis ausgeben\n",
        "import os\n",
        "initial_count = 0\n",
        "for path in os.listdir(srcpath_images):\n",
        "    if os.path.isfile(os.path.join(srcpath_images, path)):\n",
        "        initial_count += 1\n",
        "print(initial_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeXQIHeFQVxA",
        "outputId": "e595cc90-e2e8-4de9-ff24-c11b3eb69107"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "IrYo7JB4-eI1"
      },
      "outputs": [],
      "source": [
        "###################################################################\n",
        "# Parameter festlegen\n",
        "###################################################################\n",
        "\n",
        "\n",
        "####################################################################\n",
        "# Datum und Uhrzeit des Trainings\n",
        "####################################################################\n",
        "\n",
        "today = date.today()\n",
        "now = datetime.now()\n",
        "# dd/mm/yyyy\n",
        "date_of_training = today.strftime(\"%d/%m/%Y\")\n",
        "time_of_training = now.strftime(\"%H:%M:%S\")\n",
        "\n",
        "\n",
        "\n",
        "###################################################################\n",
        "# Parameter zum Training des Modells\n",
        "###################################################################\n",
        "# Gibt die Anzahl der Epochen an\n",
        "epochs_train = 100\n",
        "\n",
        "\n",
        "###################################################################\n",
        "# Parameter zum Einlesen der Daten\n",
        "###################################################################\n",
        "\n",
        "# Sollen die verwendeten Bilder in Verzeichnisse geschrieben werden?\n",
        "saving_images_to_dir = False\n",
        "\n",
        "# Sollen die Bilder Standardisiert werden?\n",
        "standardizing_images = False\n",
        "\n",
        "# Soll Preprocessing genutzt werden? Dabei werden die Bilder in s/w\n",
        "# konvertiert und mit einem Canny Filter die Kanten hervorgehoben\n",
        "preprocesing_images = False\n",
        "\n",
        "# Soll die Auflösung der Bilder im Vorfeld angepasst werden?\n",
        "resizing_images = True\n",
        "# Werte für die Resize Funktion\n",
        "# Zukünftige Maße für Querformat festlegen \n",
        "widthquer = 400\n",
        "heightquer = 300\n",
        "# Zukünftige Maße für Hochformat festlegen \n",
        "widthhoch = 300\n",
        "heighthoch = 400\n",
        "\n",
        "# In welchem Verhältnis sollen die Daten in Train-/Validationssplit\n",
        "# aufgeteilt werden?\n",
        "faktorTrainSplit = 0.8\n",
        "\n",
        "synthetic = False\n",
        "\n",
        "\n",
        "\n",
        "##################################################################################\n",
        "# Methode in der die Parameter definiert werden, welche Bilder verwendet werden sollen\n",
        "##################################################################################\n",
        "def ImageIsInFilter(splittedfilename):\n",
        "    # Welche Images sollen aus dem vorher angegebenen SrcOrdner verwendet werden. Gefiltert wird nach den Flags im Dateinamen\n",
        "    if (\n",
        "    # ( (splittedfilename[1] == str(1)) or (splittedfilename[1] == str(2)) ) and\n",
        "    # Prüft an Stelle 13 des Dateinamens auf das Flag \"1\". Damit werden nur Bilder geladen die mit dem Smartphone aufgenommen wurden\n",
        "    (splittedfilename[13] == str(1)) and\n",
        "    # Prüft an Stelle 14 des Dateinamens auf das Flag \"1\". Damit werden nur Bilder geladen die im Querformat vorliegen.\n",
        "    (splittedfilename[14] == str(1)) and\n",
        "    # Prüft an Stelle 15 des Dateinamens auf das Flag \"1\", \"2\", \"3\" und \"4\". Damit werden nur Bilder geladen die ohne, mit rotem, einem Aruco oder drei Aruco Sticker aufgenommen wurden.\n",
        "    (splittedfilename[15] == str(1))\n",
        "    #( (splittedfilename[15] == str(1)) or (splittedfilename[15] == str(2)) or (splittedfilename[15] == str(3)) or (splittedfilename[15] == str(4)) )\n",
        "    ):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "\n",
        "##################################################################################\n",
        "# Methode zum Anlegen der Ordner (keine Anpassung notwendig!)\n",
        "##################################################################################\n",
        "def createDir(path):\n",
        "    if os.path.exists(path):\n",
        "        shutil.rmtree(path, ignore_errors=False)\n",
        "    os.makedirs(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "co1jUcYV-aIa",
        "outputId": "fb17a7c2-6065-4788-d654-86ab6a92cc0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anzahl aller verwendeten Wände/Szenen: 112\n",
            "Anzahl der Wände/Szenen für das Trainingset: 89\n",
            "Anzahl der Wände/Szenen für das Validationset: 21\n",
            "Anzahl der Wände/Szenen für das Testset: 2\n",
            "\n",
            "Anzahl aller verwendeter Bilder: 421\n",
            "\n",
            "Traingset:\n",
            "Anzahl der im Array x_train_material gespeicherten Bilder: 339\n",
            "Anzahl der im Array y_train_material_putty gespeicherten Labels: 339\n",
            "y_train_material_putty Min: 1688\n",
            "y_train_material_putty Max: 12008\n",
            "y_train_material_putty Mean: 7397\n",
            "\n",
            "Validationset:\n",
            "Anzahl der im Array x_val_material gespeicherten Bilder: 79\n",
            "Anzahl der im Array y_val_material_putty gespeicherten Labels: 79\n",
            "y_val_material_putty Min: 2069\n",
            "y_val_material_putty Max: 14992\n",
            "y_val_material_putty Mean: 6604\n",
            "\n",
            "Testset:\n",
            "Anzahl der im Array x_test_material gespeicherten Bilder: 3\n",
            "Anzahl der im Array y_test_material gespeicherten Labels: 3\n",
            "y_test_material Min: 4068\n",
            "y_test_material Max: 4696\n",
            "y_test_material Mean: 4277\n"
          ]
        }
      ],
      "source": [
        "###################################################################\n",
        "# Einlesen der Daten (Bilder und Label) in Arrays\n",
        "###################################################################\n",
        "\n",
        "# Hilfslisten und Variablen zur Verteilung des Train-/Testsplits\n",
        "waende_alle = []\n",
        "waende_train = []\n",
        "waende_val = []\n",
        "waende_test = []\n",
        "# Arrays für die Images des Train- und Testsplits\n",
        "x_train_material = []\n",
        "x_val_material = []\n",
        "x_test_material = []\n",
        "\n",
        "# Arrays für die Labels des Trainsplits\n",
        "y_train_material_putty = []\n",
        "y_train_material_jointTape = []\n",
        "y_train_material_cornerProfiles = []\n",
        "# Arrays für die Labels des Validationsplits\n",
        "y_val_material_putty = []\n",
        "y_val_material_jointTape = []\n",
        "y_val_material_cornerProfiles = []\n",
        "\n",
        "# Arrays für die Labels des Testsplits\n",
        "y_test_material = []\n",
        "\n",
        "# Hilfsarray um die Dateinamen aller verwendeten Bilder zwischenzuspeichern\n",
        "images_train_filenames = []\n",
        "images_val_filenames = []\n",
        "images_test_filenames = []\n",
        "images_all_filenames = []\n",
        "\n",
        "# Legt die Ordner Struktur an\n",
        "createDir(destpath_dir)\n",
        "if saving_images_to_dir:\n",
        "  createDir(destpath_train_images)\n",
        "  createDir(destpath_val_images)\n",
        "  createDir(destpath_test_images)\n",
        "createDir(destpath_modelsave)\n",
        "createDir(destpath_logsave)\n",
        "createDir(destpath_plotsave)\n",
        "\n",
        "\n",
        "\n",
        "##################################################################################\n",
        "# Wand-Label-Info-CSV in NP Array einlesen\n",
        "##################################################################################\n",
        "# eventueller Parameter: usecols = (0,1,2,3,4,5,6)\n",
        "# eventueller Parameter: dtype=\"int\" \n",
        "\n",
        "with open(str(srcpath_label_infos)+str(csv_name), encoding=\"utf-8-sig\") as wand_label_info_file:\n",
        "    wand_label_info = np.loadtxt(wand_label_info_file, delimiter=\";\", dtype=\"int\")\n",
        "#print(wand_label_info)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##################################################################################\n",
        "# Baustellen und Wand ID aus Dateinamen laden um Train/Testsplit auf Wandebene vorzubereiten\n",
        "##################################################################################\n",
        "for filename in os.listdir(srcpath_images):\n",
        "    # Trennt den Filename in den reinen Filename und Extension\n",
        "    filenameshort, extension = os.path.splitext(filename)\n",
        "    # Prüft ob Datei .jpg ist\n",
        "    if extension == \".jpg\":\n",
        "        # Splitted den Dateinamen mit dem Trennoperator \"_\" und speichert den Inhalt in eine Liste\n",
        "        splittedfilename = filenameshort.split(\"_\")\n",
        "        # Speichert die Baustellennummer und Wandnummer zwischen\n",
        "        img_baustellenID = splittedfilename[1]\n",
        "        img_wandID = splittedfilename[2]\n",
        "        img_baustellenUndWandID = img_baustellenID+\"_\"+img_wandID\n",
        "        # Welche Images sollen aus dem vorher angegebenen SrcOrdner verwendet werden. Gefiltert wird nach den Flags im Dateinamen\n",
        "        if (ImageIsInFilter(splittedfilename)):\n",
        "            if img_baustellenUndWandID not in waende_alle:\n",
        "                waende_alle.append(img_baustellenUndWandID)\n",
        "waende_alle_count = len(waende_alle)          \n",
        "print(\"Anzahl aller verwendeten Wände/Szenen: \"+str(waende_alle_count))\n",
        "# Bestimmt die Anzahl der Wände für den Trainingssplit. Dafür wird der vorherig definierte Faktor verwendet\n",
        "waende_train, waende_uebrig = train_test_split(waende_alle, train_size=faktorTrainSplit, random_state=42)\n",
        "waende_val, waende_test = train_test_split(waende_uebrig, test_size = 0.05, random_state=42)\n",
        "\n",
        "waende_train_count = len(waende_train)\n",
        "print(\"Anzahl der Wände/Szenen für das Trainingset: \"+str(waende_train_count))\n",
        "waende_val_count = len(waende_val)\n",
        "print(\"Anzahl der Wände/Szenen für das Validationset: \"+str(waende_val_count))\n",
        "waende_test_count = len(waende_test)\n",
        "print(\"Anzahl der Wände/Szenen für das Testset: \"+str(waende_test_count))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##################################################################################\n",
        "# gewünschte Bilder werden bearbeitet und dem Train- oder Testsplit hinzugefügt\n",
        "##################################################################################\n",
        "for filename in os.listdir(srcpath_images):\n",
        "    # Trennt den Filename in den reinen Filename und Extension\n",
        "    filenameshort, extension = os.path.splitext(filename)\n",
        "    # Prüft ob Datei .jpg ist\n",
        "    if extension == \".jpg\":\n",
        "        # Splitted den Dateinamen mit dem Trennoperator \"_\" und speichert den Inhalt in eine Liste\n",
        "        splittedfilename = filenameshort.split(\"_\")\n",
        "        # Speichert die Baustellennummer und Wandnummer zwischen\n",
        "        img_baustellenID = splittedfilename[1]\n",
        "        img_wandID = splittedfilename[2]\n",
        "        img_baustellenUndWandID = img_baustellenID+\"_\"+img_wandID\n",
        "        # Welche Images sollen aus dem vorher angegebenen Src-Ordner verwendet werden. Gefiltert wird nach den Flags im Dateinamen (siehe Methode \"ImageIsInFilter\")\n",
        "        if (ImageIsInFilter(splittedfilename)):\n",
        "            # Gefilterte Bilder/Images laden\n",
        "            img = cv2.imread(os.path.join(srcpath_images,filename))\n",
        "\n",
        "\n",
        "  \n",
        " \n",
        "            ###################################################################################\n",
        "            # Preprocessing der Bilder1\n",
        "            ###################################################################################\n",
        "            if preprocesing_images:\n",
        "              imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #Bild wird schwarz weiß\n",
        "              # print(f\"Shape imgGray: {imgGray.shape}\")\n",
        "              imgBlur=cv2.GaussianBlur(imgGray,(5,5),1) #Kernel 5*5\n",
        "              # print(f\"Shape imgBlur: {imgGray.shape}\")\n",
        "              # Canny Filter: Thr = For this, we need two threshold values, minVal and maxVal. Any edges with intensity gradient more than maxVal are sure to be edges and those below minVal are sure to be non-edges, so discarded.\n",
        "              imgCanny=cv2.Canny(imgBlur, 40, 40) #Cannyfilter (25, 25 guter Wert, wenn nur Canny)\n",
        "              # print(f\"Shape imgCanny: {imgCanny.shape}\")\n",
        "              kernel= np.ones((5,5)) #Neuer Kernel für Dilate (5*5 groß)\n",
        "              imgDial = cv2.dilate(imgCanny,kernel,iterations=2) #Erweitert das Bild (verstärkt)\n",
        "              # print(f\"Shape imgDial: {imgDial.shape}\")\n",
        "              imgThre=cv2.erode(imgDial,kernel,iterations=1) #Verfeinert das Bild (verwässert)\n",
        "              # print(f\"Shape imgThre: {imgThre.shape}\")\n",
        "              img = imgThre\n",
        "\n",
        "\n",
        "            ##################################################################################\n",
        "            # Resizing der Bilder\n",
        "            ##################################################################################\n",
        "            if resizing_images:\n",
        "              # Resize der Bilder auf neue Maße wie zu Beginn angegeben\n",
        "              # Prüft ob Bild Querformat ist\n",
        "              if splittedfilename[14] == str(1):\n",
        "                  dim = (widthquer, heightquer)\n",
        "              # Prüft ob Bild Hochformat ist\n",
        "              elif splittedfilename[14] == str(2):\n",
        "                  dim = (widthhoch, heighthoch)\n",
        "              # Resize mit neuen Dimensionen\n",
        "              resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "              img = resized\n",
        "\n",
        "\n",
        "\n",
        "            ###################################################################################\n",
        "            # Speichern der Bilder in die zuvor angegebenen Zielordner  \n",
        "            ###################################################################################\n",
        "            if saving_images_to_dir:\n",
        "              if img_baustellenUndWandID in waende_train:\n",
        "                  cv2.imwrite(os.path.join(destpath_train_images , filenameshort+'.jpg'),img)\n",
        "              elif img_baustellenUndWandID in waende_val:\n",
        "                  cv2.imwrite(os.path.join(destpath_val_images , filenameshort+'.jpg'),img)\n",
        "              else:   \n",
        "                  cv2.imwrite(os.path.join(destpath_test_images , filenameshort+'.jpg'),img)\n",
        "            \n",
        "\n",
        "            ###################################################################################\n",
        "            # Standardizierung\n",
        "            ###################################################################################\n",
        "            if standardizing_images:\n",
        "              img = np.array(img, dtype=np.int64)\n",
        "              imgst = (img - np.mean(img)) / np.std(img)\n",
        "              img = imgst\n",
        "\n",
        "\n",
        "\n",
        "            ###################################################################################\n",
        "            # Preprocessing der Bilder2\n",
        "            ###################################################################################\n",
        "            if preprocesing_images:\n",
        "              # print(f\"Shape before new dimension: {img.shape}\")\n",
        "              img = tf.expand_dims(img,axis=2)\n",
        "              # print(f\"Shape after new dimension: {img.shape}\")\n",
        "\n",
        "\n",
        "\n",
        "            ##################################################################################\n",
        "            # Speichern der Bilder und der zugehörigen Labels in die Arrays des Train- und Testsets  \n",
        "            ################################################################################## \n",
        "            # Prüft ob das Bild zu den Traingswänden gehört\n",
        "            if img_baustellenUndWandID in waende_train:\n",
        "                x_train_material.append(np.array(img))\n",
        "                # Iteriert durch die Infos aus der CSV und schaut ob die BaustellenID und WandID der Dateien mit den Zeilen in der CSV matchen. Falls ja, dann soll das zugehörige \n",
        "                # Label in das Array \"y_train_material_putty\" gespeichert werden. \n",
        "                for i in range(len(wand_label_info)):\n",
        "                    # Prüft ob BaustellenID und WandID mit den Spalten in der CSV übereinstimmen.\n",
        "                    if (\n",
        "                        str(wand_label_info[i][0]) == img_baustellenID and\n",
        "                        str(wand_label_info[i][1]) == img_wandID\n",
        "                    ):\n",
        "                        # Fügt den Wert der gewählten Spalte in der CSV dem Array \"y_train_material_putty\" hinzu\n",
        "                        y_train_material_putty.append(np.array(wand_label_info[i][csv_spalte_labelinfo_putty]))\n",
        "                # Den Dateinamen des gefilterten Traings-Images in einem Array speichern. Für spätere Kontrolle nützlich\n",
        "                images_train_filenames.append(filename)\n",
        "            # Prüft ob das Bild zu den Validationwänden gehört\n",
        "            elif img_baustellenUndWandID in waende_val:\n",
        "                x_val_material.append(np.array(img))\n",
        "                # Iteriert durch die Infos aus der CSV und schaut ob die BaustellenID und WandID der Dateien mit den Zeilen in der CSV matchen. Falls ja, dann soll das zugehörige \n",
        "                # Label in das Array \"y_val_material_putty\" gespeichert werden. \n",
        "                for i in range(len(wand_label_info)):\n",
        "                    # Prüft ob BaustellenID und WandID mit den Spalten in der CSV übereinstimmen.\n",
        "                    if (\n",
        "                        str(wand_label_info[i][0]) == img_baustellenID and\n",
        "                        str(wand_label_info[i][1]) == img_wandID\n",
        "                    ):\n",
        "                        # Fügt den Wert der gewählten Spalte in der CSV dem Array \"y_train_material_putty\" hinzu\n",
        "                        y_val_material_putty.append(np.array(wand_label_info[i][csv_spalte_labelinfo_putty]))\n",
        "                # Den Dateinamen des gefilterten Traings-Images in einem Array speichern. Für spätere Kontrolle nützlich\n",
        "                images_val_filenames.append(filename)\n",
        "            # Wenn das Bild nicht zu den Trainings- oder Validationswänden gehört, gehört es zu den Testwänden          \n",
        "            else:\n",
        "                x_test_material.append(np.array(img))\n",
        "                # Iteriert durch die Infos aus der CSV und schaut ob die BaustellenID und WandID der Dateien mit den Zeilen im Array aus der eingelesen CSV matchen. Falls ja, dann soll das zugehörige \n",
        "                # Label in das Array \"y_test_material\" gespeichert werden. \n",
        "                for i in range(len(wand_label_info)):\n",
        "                    # Prüft ob BaustellenID und WandID mit den Spalten in dem Array der eingelesen CSV übereinstimmen.\n",
        "                    if (\n",
        "                        str(wand_label_info[i][0]) == img_baustellenID and\n",
        "                        str(wand_label_info[i][1]) == img_wandID\n",
        "                    ):\n",
        "                        # Fügt den Wert der gewählten Spalte in der CSV dem Array \"y_test_material\" hinzu\n",
        "                        y_test_material.append(np.array(wand_label_info[i][csv_spalte_labelinfo_putty]))\n",
        "                # Den Dateinamen des gefilterten Test-Images in einem Array speichern. Für spätere Kontrolle nützlich\n",
        "                images_test_filenames.append(filename)\n",
        "            # Den Dateinamen des gefilterten Images in einem Array speichern in dem alle verwendeten Dateinamen gespeichert werden. Für spätere Kontrolle nützlich\n",
        "            images_all_filenames.append(filename)\n",
        "\n",
        "\n",
        "##################################################################################\n",
        "# Konvertierung in NP Arrays\n",
        "################################################################################## \n",
        "images_train_filename = np.array(images_train_filenames)\n",
        "images_val_filename = np.array(images_val_filenames)\n",
        "images_test_filenames = np.array(images_test_filenames)\n",
        "images_all_filenames = np.array(images_all_filenames)\n",
        "x_train_material = np.array(x_train_material)\n",
        "y_train_material_putty = np.array(y_train_material_putty)\n",
        "x_val_material = np.array(x_val_material)\n",
        "y_val_material_putty = np.array(y_val_material_putty)\n",
        "x_test_material = np.array(x_test_material)\n",
        "y_test_material = np.array(y_test_material)\n",
        "\n",
        "\n",
        "\n",
        "##################################################################################\n",
        "# Ausgabe der Werte auf der Konsole\n",
        "################################################################################## \n",
        "print()\n",
        "images_all_count = len(images_all_filenames)\n",
        "print(\"Anzahl aller verwendeter Bilder: \"+str(images_all_count))\n",
        "print()\n",
        "\n",
        "print(\"Traingset:\")\n",
        "x_train_images_count = len(x_train_material)\n",
        "print(\"Anzahl der im Array x_train_material gespeicherten Bilder: \"+str(x_train_images_count))\n",
        "y_train_material_putty_labelcount = len(y_train_material_putty)\n",
        "print(\"Anzahl der im Array y_train_material_putty gespeicherten Labels: \"+str(y_train_material_putty_labelcount))\n",
        "y_train_material_putty_min = np.amin(y_train_material_putty)\n",
        "print(\"y_train_material_putty Min: \"+str(y_train_material_putty_min))\n",
        "y_train_material_putty_max = np.amax(y_train_material_putty)\n",
        "print(\"y_train_material_putty Max: \"+str(y_train_material_putty_max))\n",
        "y_train_material_putty_mean = round(np.mean(y_train_material_putty))\n",
        "print(\"y_train_material_putty Mean: \"+str(y_train_material_putty_mean))\n",
        "print()\n",
        "\n",
        "\n",
        "print(\"Validationset:\")\n",
        "x_val_images_count = len(x_val_material)\n",
        "print(\"Anzahl der im Array x_val_material gespeicherten Bilder: \"+str(x_val_images_count))\n",
        "y_val_material_putty_labelcount = len(y_val_material_putty)\n",
        "print(\"Anzahl der im Array y_val_material_putty gespeicherten Labels: \"+str(y_val_material_putty_labelcount))\n",
        "y_val_material_putty_min = np.amin(y_val_material_putty)\n",
        "print(\"y_val_material_putty Min: \"+str(y_val_material_putty_min))\n",
        "y_val_material_putty_max = np.amax(y_val_material_putty)\n",
        "print(\"y_val_material_putty Max: \"+str(y_val_material_putty_max))\n",
        "y_val_material_putty_mean = round(np.mean(y_val_material_putty))\n",
        "print(\"y_val_material_putty Mean: \"+str(y_val_material_putty_mean))\n",
        "print()\n",
        "\n",
        "\n",
        "print(\"Testset:\")\n",
        "print(\"Anzahl der im Array x_test_material gespeicherten Bilder: \"+str(len(x_test_material)))\n",
        "print(\"Anzahl der im Array y_test_material gespeicherten Labels: \"+str(len(y_test_material)))\n",
        "print(\"y_test_material Min: \"+str(np.amin(y_test_material)))\n",
        "print(\"y_test_material Max: \"+str(np.amax(y_test_material)))\n",
        "print(\"y_test_material Mean: \"+str(round(np.mean(y_test_material))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "GGuGUuB1-gI9"
      },
      "outputs": [],
      "source": [
        "##################################################################################\n",
        "# Definieren des Modells\n",
        "##################################################################################  \n",
        "\n",
        "if preprocesing_images:\n",
        "  # Wenn Preproccessng genutzt wird ist das Bild schwarz/weiß. Dadurch hat das Bild nur eine Tiefe von einer Schicht.\n",
        "  image_layer = 1\n",
        "else:\n",
        "  # Falls kein Preproccessing genutzt wird ist das Bild in Farbe. Dadurch hat das Bild eine Tiefe von drei Schichten.\n",
        "  image_layer = 3\n",
        "\n",
        "\n",
        "material_model = Sequential([\n",
        "\n",
        "    Conv2D(128, kernel_size=3, activation='relu', input_shape=(300, 400, image_layer)),\n",
        "\n",
        "    MaxPool2D(pool_size=3, strides=2),\n",
        "\n",
        "    Conv2D(128, kernel_size=3, activation='relu'),\n",
        "\n",
        "    MaxPool2D(pool_size=3, strides=2),\n",
        "\n",
        "    Conv2D(256, kernel_size=3, activation='relu'),\n",
        "\n",
        "    MaxPool2D(pool_size=3, strides=2),\n",
        "\n",
        "    Conv2D (512, kernel_size=3, activation='relu'),\n",
        "\n",
        "    MaxPool2D(pool_size=3, strides=2),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Dense(512, activation='relu'),\n",
        "\n",
        "    Dense(1, activation='linear', name='material')\n",
        "])\n",
        "\n",
        "material_model.compile(\n",
        "optimizer='adam',\n",
        "loss='mse',\n",
        "metrics =['mae']\n",
        ")\n",
        "\n",
        "\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.CSVLogger((destpath_logsave + \"Training_History.csv\"), separator=';', append=False)\n",
        "]\n",
        "\n",
        "# Nullt die Variable für die Größe des Modells\n",
        "modelsize_putty = 0\n",
        "\n",
        "# Speichert die Anzahl der Parameter in Variablen für die finale Evaluation\n",
        "model_trainable_parameter_count = count_params(material_model.trainable_weights)\n",
        "model_non_trainable_parameter_count = count_params(material_model.non_trainable_weights)\n",
        "model_parameter_total_count = model_trainable_parameter_count + model_non_trainable_parameter_count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "UHMtojOr-mTr"
      },
      "outputs": [],
      "source": [
        "%%capture cap_modelview --no-stderr\n",
        "with open(destpath_logsave+ \"Modellaufbau.txt\", 'w') as f:\n",
        "    f.write(cap_modelview.stdout)\n",
        "##################################################################################\n",
        "# Printen des Modells\n",
        "################################################################################## \n",
        "print(material_model.summary ())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWMwzxVeH4Lu",
        "outputId": "1b173679-d1aa-4ce8-f735-852c42abd358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 75117736.0000 - mae: 7348.4663 - val_loss: 14190668.0000 - val_mae: 2521.8140\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 22760790.0000 - mae: 3995.1953 - val_loss: 19534262.0000 - val_mae: 3931.2729\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 9462623.0000 - mae: 2534.0757 - val_loss: 14872782.0000 - val_mae: 3350.4368\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 7459698.0000 - mae: 2317.0974 - val_loss: 11806487.0000 - val_mae: 2491.1167\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 7265928.0000 - mae: 2270.7195 - val_loss: 13836343.0000 - val_mae: 3132.7712\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 7004768.0000 - mae: 2202.8535 - val_loss: 11521431.0000 - val_mae: 2463.7598\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 5815070.0000 - mae: 2026.7946 - val_loss: 12887877.0000 - val_mae: 2729.7468\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 4559064.5000 - mae: 1757.1805 - val_loss: 10123895.0000 - val_mae: 2312.3169\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 3699095.7500 - mae: 1559.2218 - val_loss: 9554250.0000 - val_mae: 2067.7549\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 3244704.7500 - mae: 1433.6323 - val_loss: 9243811.0000 - val_mae: 2133.5752\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 2981196.7500 - mae: 1388.5371 - val_loss: 8226123.5000 - val_mae: 2034.0565\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 2766850.0000 - mae: 1337.0457 - val_loss: 9246688.0000 - val_mae: 2333.1133\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 3134229.0000 - mae: 1465.7389 - val_loss: 7313701.5000 - val_mae: 1906.9656\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 2351157.2500 - mae: 1208.5471 - val_loss: 8446419.0000 - val_mae: 2026.9994\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 1986187.5000 - mae: 1123.8737 - val_loss: 7432116.0000 - val_mae: 1918.2941\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 1762301.7500 - mae: 1047.7408 - val_loss: 7860366.5000 - val_mae: 1973.4484\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 1858640.2500 - mae: 1060.6090 - val_loss: 7265273.5000 - val_mae: 2045.2164\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 1735166.1250 - mae: 1016.4447 - val_loss: 7054548.5000 - val_mae: 1920.0763\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 1433599.0000 - mae: 914.6956 - val_loss: 7950176.5000 - val_mae: 1978.4368\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 1463922.7500 - mae: 938.0213 - val_loss: 8143015.0000 - val_mae: 2120.8230\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 1555543.7500 - mae: 975.7757 - val_loss: 6955641.5000 - val_mae: 1921.5166\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 1289845.0000 - mae: 874.1505 - val_loss: 8302269.0000 - val_mae: 1987.1541\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 1330274.5000 - mae: 867.0628 - val_loss: 8540527.0000 - val_mae: 1946.0988\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 1207856.0000 - mae: 837.2218 - val_loss: 7978482.0000 - val_mae: 1917.7184\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 1120523.0000 - mae: 809.8521 - val_loss: 6800756.0000 - val_mae: 1853.3196\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 929319.3750 - mae: 710.9382 - val_loss: 7215831.5000 - val_mae: 1884.2927\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 866966.3750 - mae: 706.8218 - val_loss: 6751941.5000 - val_mae: 1865.9956\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 909123.7500 - mae: 708.5840 - val_loss: 7376760.0000 - val_mae: 1965.2919\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 1323703.5000 - mae: 926.1143 - val_loss: 7188603.0000 - val_mae: 1894.8230\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 892494.9375 - mae: 734.0787 - val_loss: 7706967.5000 - val_mae: 1948.5909\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 796086.7500 - mae: 681.4764 - val_loss: 7553427.5000 - val_mae: 1914.8837\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 807725.1875 - mae: 682.8960 - val_loss: 7460501.0000 - val_mae: 1925.9283\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 842146.0000 - mae: 683.7523 - val_loss: 7575554.5000 - val_mae: 1940.0724\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 748414.7500 - mae: 657.8495 - val_loss: 8244451.0000 - val_mae: 2054.3442\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 907589.7500 - mae: 738.7322 - val_loss: 8158089.5000 - val_mae: 1946.5524\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 764614.5625 - mae: 676.8066 - val_loss: 8544690.0000 - val_mae: 1977.2877\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 835223.5000 - mae: 715.1955 - val_loss: 7114693.5000 - val_mae: 1916.4518\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 635108.1250 - mae: 603.9912 - val_loss: 6188495.5000 - val_mae: 1867.9971\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 602168.1875 - mae: 596.4858 - val_loss: 7238684.5000 - val_mae: 1935.4298\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 649587.6250 - mae: 631.1356 - val_loss: 6830257.5000 - val_mae: 1891.2539\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 812206.4375 - mae: 718.2551 - val_loss: 6977419.5000 - val_mae: 1914.5779\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 538549.5000 - mae: 564.1858 - val_loss: 7319356.0000 - val_mae: 1901.6981\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 469842.5000 - mae: 512.5787 - val_loss: 6707743.0000 - val_mae: 1850.2299\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 406894.4062 - mae: 465.8316 - val_loss: 6561754.5000 - val_mae: 1837.8046\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 418963.7812 - mae: 470.9082 - val_loss: 7532517.5000 - val_mae: 1899.7249\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 631317.6250 - mae: 600.1351 - val_loss: 7344564.5000 - val_mae: 1930.2168\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 592806.3125 - mae: 570.8953 - val_loss: 8306576.0000 - val_mae: 1958.7231\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 571622.8125 - mae: 563.1411 - val_loss: 7741904.0000 - val_mae: 1913.3107\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 557816.9375 - mae: 577.4764 - val_loss: 7289506.0000 - val_mae: 1903.4739\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 414250.4688 - mae: 483.4884 - val_loss: 6500204.5000 - val_mae: 1833.7191\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 330362.5000 - mae: 424.3293 - val_loss: 6769882.5000 - val_mae: 1857.4911\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 353178.1562 - mae: 439.8739 - val_loss: 6136058.5000 - val_mae: 1801.8091\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 357170.5938 - mae: 449.8330 - val_loss: 7110808.5000 - val_mae: 1896.4436\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 413110.4062 - mae: 480.2375 - val_loss: 6646934.5000 - val_mae: 1837.2528\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 390568.4062 - mae: 457.9911 - val_loss: 6554513.0000 - val_mae: 1825.1343\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 300498.4688 - mae: 400.2393 - val_loss: 6275294.0000 - val_mae: 1807.3944\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 353365.4375 - mae: 439.3899 - val_loss: 6571384.0000 - val_mae: 1836.4824\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 313521.2188 - mae: 411.4542 - val_loss: 6791387.0000 - val_mae: 1857.4825\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 288742.5938 - mae: 388.3450 - val_loss: 6563095.0000 - val_mae: 1827.5969\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 275261.8125 - mae: 395.8227 - val_loss: 6579880.5000 - val_mae: 1820.1221\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 243863.1562 - mae: 366.9163 - val_loss: 6258574.5000 - val_mae: 1814.4987\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 282056.0938 - mae: 387.5689 - val_loss: 7046786.5000 - val_mae: 1857.4094\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 289827.6562 - mae: 404.5559 - val_loss: 6022299.5000 - val_mae: 1805.0206\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 327823.6562 - mae: 437.6944 - val_loss: 6308924.0000 - val_mae: 1816.9484\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 263397.9062 - mae: 382.8018 - val_loss: 6345774.0000 - val_mae: 1793.3954\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 305097.9062 - mae: 416.6361 - val_loss: 6501483.5000 - val_mae: 1866.5742\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 339425.0000 - mae: 440.2410 - val_loss: 6651484.5000 - val_mae: 1835.7638\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 247793.2500 - mae: 377.4787 - val_loss: 5807425.0000 - val_mae: 1757.1689\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 267459.0000 - mae: 392.4773 - val_loss: 5788793.0000 - val_mae: 1792.5890\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 210725.2188 - mae: 347.7662 - val_loss: 6357157.0000 - val_mae: 1825.3354\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 206676.7188 - mae: 331.8629 - val_loss: 6505782.0000 - val_mae: 1860.0258\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 237215.7188 - mae: 374.7087 - val_loss: 6887089.5000 - val_mae: 1873.3865\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 248185.5781 - mae: 384.1281 - val_loss: 5918486.0000 - val_mae: 1783.7065\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 300664.0625 - mae: 419.2905 - val_loss: 6005813.5000 - val_mae: 1810.0580\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 541105.8125 - mae: 596.6247 - val_loss: 7001860.0000 - val_mae: 1922.4187\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 465453.3125 - mae: 537.2637 - val_loss: 7323930.0000 - val_mae: 1893.9814\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 578929.3750 - mae: 598.7249 - val_loss: 7427815.0000 - val_mae: 1960.9789\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 519871.1562 - mae: 564.4443 - val_loss: 8635159.0000 - val_mae: 2017.9747\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 444755.2500 - mae: 501.9840 - val_loss: 7497093.0000 - val_mae: 1993.9946\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 316225.9375 - mae: 424.3044 - val_loss: 6323669.5000 - val_mae: 1823.4371\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 323664.7812 - mae: 427.8532 - val_loss: 6687869.0000 - val_mae: 1898.4426\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 270252.0000 - mae: 370.0164 - val_loss: 6337710.0000 - val_mae: 1821.6215\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 258914.1719 - mae: 375.5772 - val_loss: 5894616.5000 - val_mae: 1738.1935\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 278131.3750 - mae: 401.2383 - val_loss: 7144620.5000 - val_mae: 1948.5431\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 338030.8750 - mae: 432.2169 - val_loss: 6125866.5000 - val_mae: 1786.6909\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 249916.5000 - mae: 377.4512 - val_loss: 6569711.5000 - val_mae: 1826.9055\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 188100.5781 - mae: 324.0266 - val_loss: 6211044.0000 - val_mae: 1824.2919\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 171346.5312 - mae: 309.6628 - val_loss: 6731480.5000 - val_mae: 1889.4764\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 286235.6562 - mae: 412.7785 - val_loss: 6780883.5000 - val_mae: 1876.0583\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 240200.2656 - mae: 366.0482 - val_loss: 7469637.5000 - val_mae: 1956.2034\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 265964.8125 - mae: 387.0289 - val_loss: 7361219.0000 - val_mae: 1899.0603\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 196175.3438 - mae: 326.8161 - val_loss: 6348355.5000 - val_mae: 1828.8033\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 278317.4375 - mae: 404.7230 - val_loss: 6888270.5000 - val_mae: 1926.0188\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 301437.0000 - mae: 424.7125 - val_loss: 5670830.5000 - val_mae: 1818.3829\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 222607.3125 - mae: 336.9834 - val_loss: 7600573.5000 - val_mae: 1950.9423\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 242642.1406 - mae: 363.5295 - val_loss: 7181761.0000 - val_mae: 1926.1744\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 316066.2500 - mae: 426.7618 - val_loss: 7480730.5000 - val_mae: 2026.6310\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 354937.4062 - mae: 468.6137 - val_loss: 7571862.5000 - val_mae: 2052.9065\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 237119.2656 - mae: 372.2332 - val_loss: 6260443.0000 - val_mae: 1840.4458\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 172533.2656 - mae: 311.5515 - val_loss: 6499640.0000 - val_mae: 1824.8929\n"
          ]
        }
      ],
      "source": [
        "##################################################################################\n",
        "# Training des Modells\n",
        "################################################################################## \n",
        "\n",
        "# # Packt ein Wrapper um das Modell um es regelmäßig abzuspeichern. Dabei wird auch die History unter dem Dateipfad gespeichert\n",
        "# resumable_model = ResumableModel(material_model, save_every_epochs=50, to_path= (modelsavetemppath+\"material_model_temp.h5\"))\n",
        "\n",
        "# Training des Modells\n",
        "# history = resumable_model.fit(x=x_train_material, y=y_train_material_putty, validation_data=(x_val_material, y_val_material_putty), batch_size=32, shuffle=True, epochs=ep)\n",
        "training_material_putty = material_model.fit(x=x_train_material, y=y_train_material_putty, validation_data=(x_val_material, y_val_material_putty), batch_size=32, shuffle=True, epochs=epochs_train, callbacks=my_callbacks)\n",
        "\n",
        "\n",
        "\n",
        "# # Laden der letzten Version des Modells um damit später zu evaluieren\n",
        "# material_model = tf.keras.models.load_model(modelsavetemppath+\"material_model_temp.h5\")\n",
        "# print(\"final trainiertes Modell geladen\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eKocRUXH4Lw",
        "outputId": "5b813377-cf36-4e34-c973-0e6f4cc4cfcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final trainiertes Modell gespeichert\n"
          ]
        }
      ],
      "source": [
        "##################################################################################\n",
        "# Finales speichern des Modells\n",
        "################################################################################## \n",
        "destpath_model = destpath_modelsave + \"material_model_final.h5\"\n",
        "material_model.save(destpath_model)\n",
        "modelsize_putty = os.path.getsize(destpath_model)\n",
        "modelsize_putty = modelsize_putty / 1048576\n",
        "modelsize_putty = round(modelsize_putty, 2)\n",
        "print(\"final trainiertes Modell gespeichert\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ikjdr3EBH4Lx",
        "outputId": "899d5745-8038-4558-90f8-4b3533ee6669"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "##################################################################################\n",
        "# Plotten und Speichern der Trainings-History des Modells\n",
        "################################################################################## \n",
        "\n",
        "#plt.plot(training_material_putty.history['loss'])\n",
        "#plt.plot(training_material_putty.history['val_loss'])\n",
        "plt.plot(training_material_putty.history['mae'])\n",
        "plt.plot(training_material_putty.history['val_mae'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['loss', 'val_loss', 'mae', 'val_mae'], loc='upper right')\n",
        "\n",
        "plt.savefig(destpath_plotsave + 'mae_vs_val_mae.png')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ##################################################################################\n",
        "# # Plotten der Trainings-History des Modells\n",
        "# ##################################################################################\n",
        "# plt.plot(training_material.history['mae'])\n",
        "# plt.plot(training_material.history['val_mae'])\n",
        "# plt.title('Abweichung')\n",
        "# plt.ylabel('MAE')\n",
        "# plt.xlabel('Epoche')\n",
        "# plt.legend(['Training', 'Validierung'], loc='upper left')\n",
        "\n",
        "\n",
        "# ##################################################################################\n",
        "# # Speichert den Plot\n",
        "# ##################################################################################\n",
        "# plt.savefig(plotsavepath + 'mae_vs_val_mae.png')\n",
        "# plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################################\n",
        "# Evaluieren der einzelnen Bilder des Trainingsplit per predict\n",
        "##################################################################################\n",
        "i = 0\n",
        "evaluation_train = []\n",
        "while i < len(x_train_material):\n",
        "\n",
        "  x = x_train_material[i]\n",
        "  x = tf.expand_dims(x,axis=0)\n",
        "  actual_need = y_train_material_putty[i]\n",
        "  result = material_model.predict(x)\n",
        "  result = round(result[0][0])\n",
        "  deviation = abs(actual_need-result)\n",
        "\n",
        "  row = []\n",
        "  row.append(images_train_filenames[i])\n",
        "  row.append(actual_need)\n",
        "  row.append(result)\n",
        "  row.append(deviation)\n",
        "\n",
        "  evaluation_train.append(row)\n",
        "  i += 1\n",
        "\n",
        "evaluation_train = sorted(evaluation_train, key=lambda x:x[3])\n",
        "\n",
        "with open(destpath_logsave + \"Evaluation_Train.csv\", 'w', newline='', encoding='utf-8-sig') as f_object:  \n",
        "    writer_object = writer(f_object, delimiter=\";\")\n",
        "    writer_object.writerow([\"Dateiname\", \"Tatsächlicher Materialbedarf in g\", \"geschätzer Materialbedarf in g\", \"Abweichung Materialbedarf in g\"])\n",
        "    writer_object.writerows(evaluation_train)  \n",
        "    f_object.close()"
      ],
      "metadata": {
        "id": "h2a46UDNFcs5"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################################\n",
        "# Evaluieren der einzelnen Bilder des Validationsplit per predict\n",
        "##################################################################################\n",
        "i = 0\n",
        "evaluation_val = []\n",
        "while i < len(x_val_material):\n",
        "\n",
        "  x = x_val_material[i]\n",
        "  x = tf.expand_dims(x,axis=0)\n",
        "  actual_need = y_val_material_putty[i]\n",
        "  result = material_model.predict(x)\n",
        "  result = round(result[0][0])\n",
        "  deviation = abs(actual_need-result)\n",
        "\n",
        "  row = []\n",
        "  row.append(images_val_filenames[i])\n",
        "  row.append(actual_need)\n",
        "  row.append(result)\n",
        "  row.append(deviation)\n",
        "\n",
        "  evaluation_val.append(row)\n",
        "  i += 1\n",
        "\n",
        "evaluation_val = sorted(evaluation_val, key=lambda x:x[3])\n",
        "\n",
        "with open(destpath_logsave + \"Evaluation_Validation.csv\", 'w', newline='', encoding='utf-8-sig') as f_object:  \n",
        "    writer_object = writer(f_object, delimiter=\";\")\n",
        "    writer_object.writerow([\"Dateiname\", \"Tatsächlicher Materialbedarf in g\", \"geschätzer Materialbedarf in g\", \"Abweichung Materialbedarf in g\"])\n",
        "    writer_object.writerows(evaluation_val)  \n",
        "    f_object.close()"
      ],
      "metadata": {
        "id": "UHJJZh6f0esJ"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################################\n",
        "# Evaluieren des Modells \n",
        "##################################################################################\n",
        "\n",
        "y_train_material_putty_mae = round(training_material_putty.history['mae'][-1])\n",
        "y_train_material_putty_share = round((y_train_material_putty_mae / y_train_material_putty_mean), 3)\n",
        "y_val_material_putty_mae = round(training_material_putty.history['val_mae'][-1])\n",
        "y_val_material_putty_share = round((y_val_material_putty_mae / y_val_material_putty_mean), 3)\n",
        "\n",
        "trainingcount = \"Training \" + str(numberoftraining)\n",
        "images_format = str(widthquer) + \"x\" + str(heightquer)  \n",
        "\n",
        "var_list = [\n",
        "    date_of_training, #vorher var1\n",
        "    time_of_training, # vorher var2\n",
        "    trainingcount, #vorher var3\n",
        "    model_parameter_total_count, #vorher var4\n",
        "    modelsize_putty, # vorher var5\n",
        "    epochs_train, #vorher var6\n",
        "    standardizing_images, #vorher var7\n",
        "    preprocesing_images,\n",
        "    resizing_images,\n",
        "    waende_alle_count,\n",
        "    waende_train_count,\n",
        "    waende_val_count, \n",
        "    images_all_count, #vorher var8\n",
        "    x_train_images_count, #vorher var9\n",
        "    x_val_images_count, #vorher var10\n",
        "    images_format,\n",
        "    y_train_material_putty_mean, #vorher var12\n",
        "    y_train_material_putty_mae, # vorher var13\n",
        "    y_train_material_putty_share, # vorher var14\n",
        "    y_val_material_putty_mean, # vorher var15\n",
        "    y_val_material_putty_mae, # vorher var16\n",
        "    y_val_material_putty_share, # vorher var17\n",
        "]\n",
        "\n",
        "if os.path.exists(path_eval) == False:\n",
        "  with open(path_eval, 'w', newline='', encoding='utf-8-sig') as f_object:\n",
        "    writer_object = writer(f_object, delimiter=\";\")\n",
        "    writer_object.writerow([\"Trainingsdatum\", \n",
        "                            \"Trainingszeitpunkt\", \n",
        "                            \"Trainingsnummer\", \n",
        "                            \"Anzahl der Parameter des Modells\", \n",
        "                            \"Modellgröße in MB\", \n",
        "                            \"Trainierte Epochen\", \n",
        "                            \"Standardisierung\", \n",
        "                            \"Preprocessing\",\n",
        "                            \"Resize\", \n",
        "                            \"Anzahl aller Wände/Szenen\", \n",
        "                            \"Wände Trainingsplit\", \n",
        "                            \"Wände Validationsplit\", \n",
        "                            \"Anzahl aller Bilder\", \n",
        "                            \"Bilder Trainingsplit\", \n",
        "                            \"Bilder Validationsplit\", \n",
        "                            \"Auflösung der Bilder\",\n",
        "                            \"Mean Trainingsplit Spachtelmasse\", \n",
        "                            \"Mae Trainingsplit Spachtelmasse\", \n",
        "                            \"Mae/Mean Verhältnis Trainingsplit Spachtelmasse in %\", \n",
        "                            \"Mean Validationsplit Spachtelmasse\",\n",
        "                            \"Mae Validationplit Spachtelmasse\", \n",
        "                            \"Mae/Mean Verhältnis Trainingsplit Spachtelmasse in %\" \n",
        "                            ])\n",
        "\n",
        "with open(path_eval, 'a', newline='', encoding='utf-8-sig') as f_object:  \n",
        "  writer_object = writer(f_object, delimiter=\";\")\n",
        "  writer_object.writerow(var_list)  \n",
        "  f_object.close()"
      ],
      "metadata": {
        "id": "RbaNLxLvIV1h"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture cap_train --no-stderr\n",
        "with open(destpath_logsave+ \"Evaluation_Trainingset_PredictProBild.txt\", 'w') as f:\n",
        "    f.write(cap_train.stdout)\n",
        "\n",
        "##################################################################################\n",
        "# Evaluieren des Modells (einzeln per Predict) (Trainingset)\n",
        "################################################################################## \n",
        "\n",
        "# Trainingset\n",
        "print(\"Trainingset: \")\n",
        "print()\n",
        "i = 0\n",
        "while i < len(x_train_material):\n",
        "  print(\"Bild: \"+str(images_train_filenames[i]))\n",
        "  x = x_train_material[i]\n",
        "  x = tf.expand_dims(x,axis=0)\n",
        "  result = material_model.predict(x)\n",
        "  print(\"Vorhergesagter Materialbedarf in g: \"+str(round(result[0][0])))\n",
        "  print(\"Tatsächlicher Materialbedarf in g: \"+str(y_train_material_putty[i]))\n",
        "  print()\n",
        "  i += 1"
      ],
      "metadata": {
        "id": "ydnTyRh1u321"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture cap_validation --no-stderr\n",
        "with open(destpath_logsave+ \"Evaluation_Validationset_PredictProBild.txt\", 'w') as f:\n",
        "    f.write(cap_validation.stdout)\n",
        "\n",
        "##################################################################################\n",
        "# Evaluieren des Modells (einzeln per Predict) (Validation- und Testset)\n",
        "################################################################################## \n",
        "\n",
        "# Validationset\n",
        "print(\"Validationset: \")\n",
        "print()\n",
        "i = 0\n",
        "while i < len(x_val_material):\n",
        "  print(\"Bild: \"+str(images_val_filenames[i]))\n",
        "  x = x_val_material[i]\n",
        "  x = tf.expand_dims(x,axis=0)\n",
        "  result = material_model.predict(x)\n",
        "  print(\"Vorhergesagter Materialbedarf in g: \"+str(result[0][0]))\n",
        "  print(\"Tatsächlicher Materialbedarf in g: \"+str(y_val_material_putty[i]))\n",
        "  print()\n",
        "  i = i + 1\n",
        "\n",
        "# Testset\n",
        "print()\n",
        "print()\n",
        "print()\n",
        "print(\"Testset: \")\n",
        "i = 0\n",
        "while i < len(x_test_material):\n",
        "  print(\"Bild: \"+str(images_test_filenames[i]))\n",
        "  x = x_test_material[i]\n",
        "  x = tf.expand_dims(x,axis=0)\n",
        "  result = material_model.predict(x)\n",
        "  print(\"Vorhergesagter Materialbedarf in g: \"+str(result[0][0]))\n",
        "  print(\"Tatsächlicher Materialbedarf in g: \"+str(y_test_material[i]))\n",
        "  print()\n",
        "  i = i + 1"
      ],
      "metadata": {
        "id": "aKkKcUWXnXS0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36_PPvudH4L0",
        "outputId": "933159b2-55aa-4a75-f958-1dddb67cdd59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vorhersage Flugzeugbild: [[3787.275]]\n",
            "Vorhersage Autobild: [[4927.784]]\n",
            "Vorhersage Gipswandbild (Baustelle2 Wand10): [[6433.505]] (Tatsächlicher Materialbedarf = 6627g)\n"
          ]
        }
      ],
      "source": [
        "##################################################################################\n",
        "# Predict\n",
        "################################################################################## \n",
        "\n",
        "srcpath_predict_images = \"/content/drive/My Drive/Predict/\"\n",
        "\n",
        "imgToPredict = cv2.imread(srcpath_predict_images+\"flugzeug.jpg\")\n",
        "imgToPredict = cv2.resize(imgToPredict, (400, 300), interpolation = cv2.INTER_AREA)\n",
        "#print(f\"Shape before new dimension: {imgToPredict.shape}\")\n",
        "imgToPredict = tf.expand_dims(imgToPredict,axis=0)\n",
        "#print(f\"Shape after new dimension: {imgToPredict.shape}\")\n",
        "result = material_model.predict(imgToPredict)\n",
        "print(\"Vorhersage Flugzeugbild: \"+str(result))\n",
        "\n",
        "imgToPredict = cv2.imread(srcpath_predict_images+\"auto.jpg\")\n",
        "imgToPredict = cv2.resize(imgToPredict, (400, 300), interpolation = cv2.INTER_AREA)\n",
        "#print(f\"Shape before new dimension: {imgToPredict.shape}\")\n",
        "imgToPredict = tf.expand_dims(imgToPredict,axis=0)\n",
        "#print(f\"Shape after new dimension: {imgToPredict.shape}\")\n",
        "result = material_model.predict(imgToPredict)\n",
        "print(\"Vorhersage Autobild: \"+str(result))\n",
        "\n",
        "imgToPredict = cv2.imread(srcpath_predict_images+\"gipswand.jpg\")\n",
        "imgToPredict = cv2.resize(imgToPredict, (400, 300), interpolation = cv2.INTER_AREA)\n",
        "#print(f\"Shape before new dimension: {imgToPredict.shape}\")\n",
        "imgToPredict = tf.expand_dims(imgToPredict,axis=0)\n",
        "#print(f\"Shape after new dimension: {imgToPredict.shape}\")\n",
        "result = material_model.predict(imgToPredict)\n",
        "print(\"Vorhersage Gipswandbild (Baustelle2 Wand10): \"+str(result)+\" (Tatsächlicher Materialbedarf = 6627g)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "y3ldK5qT-rbl"
      },
      "outputs": [],
      "source": [
        "%%capture cap_allgemein --no-stderr\n",
        "with open(destpath_logsave+ \"Evaluation_Allgemein.txt\", 'w') as f:\n",
        "    f.write(cap_allgemein.stdout)\n",
        "\n",
        "##################################################################################\n",
        "# Evaluieren des Modells (Allgemein)\n",
        "################################################################################## \n",
        "print(\"Evaluation Validationset:\")\n",
        "val_material = material_model.evaluate(x_val_material, y_val_material_putty)\n",
        "print()\n",
        "print(\"Evaluation Testset:\")\n",
        "test_material = material_model.evaluate(x_test_material, y_test_material)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}