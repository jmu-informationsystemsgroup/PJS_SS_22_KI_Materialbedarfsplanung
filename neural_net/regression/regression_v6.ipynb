{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iud8HBobU3pn"
      },
      "source": [
        "# Regression_v6 Trainingsskript\n",
        "\n",
        "Mit diesem Jupyter Notebook Skript können Modelle für Spachtelmasse und Fugendeckstreifen trainiert werden. Das Skript ist für die Verwendung in Google Colab optimiert. Bilddaten und Labelinformationstabelle wurden im Vorfeld in Google Drive hochgeladen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4aJnwt4URGR"
      },
      "source": [
        "Mit dieser Zelle werden die notwendigen Pakete importiert."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vyKYTIBl9gNj"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import date, datetime\n",
        "from random import shuffle\n",
        "\n",
        "import csv\n",
        "from csv import writer\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from keras.utils.layer_utils import count_params\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Dropout, Flatten\n",
        "from keras import backend as K \n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jA91pB_VrKv"
      },
      "source": [
        "Diese Zelle importiert die verwendeten Methoden. Es sind mehrere Hilfsmethoden sowie die Hauptmethode *doTrainingwithParameters* an welche die Trainingsparameter übergeben werden können. Die Funktion der Methoden ist in den Kommentaren erklärt. Für ein Training ist keine Anpassung in der Zelle erforderlich. Ein Training kann über die nachfolgenden Zellen erfolgen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IrYo7JB4-eI1"
      },
      "outputs": [],
      "source": [
        "from matplotlib.bezier import split_bezier_intersecting_with_closedpath\n",
        "##################################################################################\n",
        "# Methoden (keine Anpassung notwendig!)\n",
        "##################################################################################\n",
        "\n",
        "##################################################################################\n",
        "# Methoden zum überprüfen der Bilder (Keine Anpassung notwendig)\n",
        "##################################################################################\n",
        "\n",
        "def check_synthetic_mirror(splittedfilename):\n",
        "    if (splittedfilename[4] == str(2)):\n",
        "      return True\n",
        "    return False  \n",
        "\n",
        "def check_synthetic_rotation(splittedfilename):\n",
        "    if (splittedfilename[5] == str(2)):\n",
        "      return True\n",
        "    return False  \n",
        "\n",
        "def check_synthetic_noise(splittedfilename):\n",
        "    if (splittedfilename[6] == str(2)):\n",
        "      return True\n",
        "    return False  \n",
        "\n",
        "def check_synthetic_brightness(splittedfilename):\n",
        "    if (splittedfilename[8] == str(2) or splittedfilename[8] == str(3)):\n",
        "      return True\n",
        "    return False  \n",
        "\n",
        "def check_synthetic_sharpness(splittedfilename):\n",
        "    if (splittedfilename[10] == str(2) or splittedfilename[10] == str(3)):\n",
        "      return True\n",
        "    return False  \n",
        "\n",
        "def check_images_with_sticker(splittedfilename):\n",
        "    if (splittedfilename[15] == str(2) or splittedfilename[15] == str(3) or splittedfilename[15] == str(4)):\n",
        "      return True\n",
        "    return False  \n",
        "\n",
        "def check_images_taken_with_DSLR(splittedfilename):\n",
        "    if (splittedfilename[13] == str(2)):\n",
        "      return True\n",
        "    return False  \n",
        "\n",
        "def check_images_taken_with_Smartphone(splittedfilename):\n",
        "    if (splittedfilename[13] == str(1)):\n",
        "      return True\n",
        "    return False  \n",
        "\n",
        "def check_images_taken_format_landscape(splittedfilename):\n",
        "    if (splittedfilename[14] == str(1)):\n",
        "      return True\n",
        "    return False  \n",
        "\n",
        "def check_images_taken_format_portrait(splittedfilename):\n",
        "    if (splittedfilename[14] == str(2)):\n",
        "      return True\n",
        "    return False  \n",
        "\n",
        "def check_ImageIsOriginal(splittedfilename):\n",
        "    if ((splittedfilename[4] == str(1)) and\n",
        "    (splittedfilename[5] == str(1)) and\n",
        "    (splittedfilename[6] == str(1)) and\n",
        "    (splittedfilename[7] == str(1)) and\n",
        "    (splittedfilename[8] == str(1)) and\n",
        "    (splittedfilename[9] == str(1)) and\n",
        "    (splittedfilename[10] == str(1)) and\n",
        "    (splittedfilename[11] == str(1)) and\n",
        "    (splittedfilename[12] == str(1)) and\n",
        "    (splittedfilename[15] == str(1))\n",
        "    ):\n",
        "      return True\n",
        "    return False  \n",
        "\n",
        "\n",
        "##################################################################################\n",
        "# Methode zum überprüfen welche Bilder verwendet werden sollen (keine Anpassung notwendig!)\n",
        "##################################################################################\n",
        "def check_ImageIsInFilter(splittedfilename, images_with_sticker, images_taken_with_DSLR, images_taken_with_Smartphone, \n",
        "                    images_taken_format_landscape, images_taken_format_portrait, synthetic_images_mirror, \n",
        "                    synthetic_images_rotation, synthetic_images_noise, synthetic_images_brightness, synthetic_images_sharpness):\n",
        "\n",
        "    synthetic_checked_mirror = check_synthetic_mirror(splittedfilename)\n",
        "    synthetic_checked_rotation = check_synthetic_rotation(splittedfilename)\n",
        "    synthetic_checked_noise = check_synthetic_noise(splittedfilename)\n",
        "    synthetic_checked_brightness = check_synthetic_brightness(splittedfilename)\n",
        "    synthetic_checked_sharpness = check_synthetic_sharpness(splittedfilename)\n",
        "    images_with_sticker_checked = check_images_with_sticker(splittedfilename)\n",
        "    images_taken_with_DSLR_checked = check_images_taken_with_DSLR(splittedfilename)\n",
        "    images_taken_with_Smartphone_checked = check_images_taken_with_Smartphone(splittedfilename)\n",
        "    images_taken_format_landscape_checked = check_images_taken_format_landscape(splittedfilename)\n",
        "    images_taken_format_portrait_checked = check_images_taken_format_portrait(splittedfilename)\n",
        "\n",
        "    if (synthetic_images_mirror == 0 and synthetic_checked_mirror == True):\n",
        "        return False\n",
        "    if (synthetic_images_rotation == 0 and synthetic_checked_rotation == True):\n",
        "        return False\n",
        "    if (synthetic_images_noise == 0 and synthetic_checked_noise == True):\n",
        "        return False\n",
        "    if (synthetic_images_brightness == 0 and synthetic_checked_brightness == True):\n",
        "        return False\n",
        "    if (synthetic_images_sharpness == 0 and synthetic_checked_sharpness == True):\n",
        "        return False\n",
        "    if (images_with_sticker == 0 and images_with_sticker_checked == True):\n",
        "        return False\n",
        "    if (images_taken_with_DSLR == 0 and images_taken_with_DSLR_checked == True):\n",
        "        return False\n",
        "    if (images_taken_with_Smartphone == 0 and images_taken_with_Smartphone_checked == True):\n",
        "        return False\n",
        "    if (images_taken_format_landscape == 0 and images_taken_format_landscape_checked == True):\n",
        "        return False\n",
        "    if (images_taken_format_portrait == 0 and images_taken_format_portrait_checked == True):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "\n",
        "##################################################################################\n",
        "# Methoden zum Anlegen der Ordner (keine Anpassung notwendig!)\n",
        "##################################################################################\n",
        "def createDirDeleteOldDir(path):\n",
        "    if os.path.exists(path):\n",
        "        shutil.rmtree(path, ignore_errors=False)\n",
        "    os.makedirs(path)\n",
        "\n",
        "def createDirIfNotExists(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def doTrainingwithParameters(srcpath_images, srcpath_label_infos, csv_name, csv_spalte_labelinfo, destpath_dir, evalpath_output, model_number, \n",
        "                        epochs_train, training_number, images_with_sticker, images_taken_with_DSLR, images_taken_with_Smartphone, \n",
        "                        images_taken_format_landscape, images_taken_format_portrait, synthetic_images_mirror, \n",
        "                        synthetic_images_rotation, synthetic_images_noise, synthetic_images_brightness, synthetic_images_sharpness, \n",
        "                        saving_images_to_dir, saving_model_to_dir, normalizing_images, standardizing_images, preprocesing_images, resizing_images, widthquer, heightquer, faktorTrainSplit):\n",
        " \n",
        "    #Delete Model / Clear session\n",
        "    K.clear_session()\n",
        "\n",
        "    ####################################################################\n",
        "    # Datum und Uhrzeit des Trainings\n",
        "    ####################################################################\n",
        "    today = date.today()\n",
        "    now = datetime.now()\n",
        "    # dd/mm/yyyy\n",
        "    date_of_training = today.strftime(\"%d/%m/%Y\")\n",
        "    time_of_training = now.strftime(\"%H:%M:%S\")\n",
        "\n",
        "    ###############################################\n",
        "    # Gibt den Zielpfad für Infos des Trainings an\n",
        "    ###############################################\n",
        "    destpath_batchplots = destpath_dir + \"Plots/\"\n",
        "    destpath_dir = destpath_dir + \"Training\" + str(training_number) + \"/\"\n",
        "    # Gibt die Pfade zum Zwischenspeichern der verwendeten Bilder an\n",
        "    # VORSICHT! ORDNER WERDEN BEIM START DES SKRIPTS GELÖSCHT/GELEERT!\n",
        "    destpath_train_images = destpath_dir + \"Dataset/Trainingset/\"\n",
        "    destpath_val_images = destpath_dir + \"Dataset/Validationset/\"\n",
        "    # Gibt den Pfad zum speichern des trainierten Modells an\n",
        "    destpath_modelsave = destpath_dir + \"models/\"\n",
        "    # Gibt den Pfad zum Speichern der Modell-Plots an\n",
        "    destpath_plotsave = destpath_dir + \"Plot/\"\n",
        "    destpath_logsave = destpath_dir + \"Logs/\"\n",
        "\n",
        "\n",
        "    ###################################################################\n",
        "    # Einlesen der Daten (Bilder und Label) in Arrays\n",
        "    ###################################################################\n",
        "\n",
        "    # Hilfslisten und Variablen zur Verteilung des Train-/Testsplits\n",
        "    waende_alle = []\n",
        "    waende_train = []\n",
        "    waende_val = []\n",
        "    # Arrays für die Images des Train- und Validationsplits\n",
        "    x_train_material = []\n",
        "    x_val_material = []\n",
        "    # Array für die Labels des Train- und Validationsplits\n",
        "    y_train_material = []\n",
        "    y_val_material = []\n",
        "\n",
        "    # Hilfsarray um die Dateinamen aller verwendeten Bilder zwischenzuspeichern\n",
        "    images_train_filenames = []\n",
        "    images_val_filenames = []\n",
        "    images_all_filenames = []\n",
        "\n",
        "    # Legt die Ordner Struktur an\n",
        "    createDirIfNotExists(destpath_batchplots)\n",
        "    createDirDeleteOldDir(destpath_dir)\n",
        "    if saving_images_to_dir == 1:\n",
        "      createDirDeleteOldDir(destpath_train_images)\n",
        "      createDirDeleteOldDir(destpath_val_images)\n",
        "    createDirDeleteOldDir(destpath_modelsave)\n",
        "    createDirDeleteOldDir(destpath_logsave)\n",
        "    createDirDeleteOldDir(destpath_plotsave)\n",
        "\n",
        "\n",
        "    ##################################################################################\n",
        "    # Wand-Label-Info-CSV in NP Array einlesen\n",
        "    ##################################################################################\n",
        "    with open(str(srcpath_label_infos)+str(csv_name)) as wand_label_info_file:\n",
        "        wand_label_info = np.loadtxt(wand_label_info_file, delimiter=\";\", skiprows=1, dtype=\"int\")\n",
        "\n",
        "\n",
        "    ##################################################################################\n",
        "    # Ausgabe Parameter und Infos auf der Konsole\n",
        "    ##################################################################################\n",
        "    print()\n",
        "    print(\"############################################################################################\")\n",
        "    print(\"#                                                                                          #\")\n",
        "    print(\"#                                  Training \"+str(training_number)+\"                                             #\")\n",
        "    print(\"#                                                                                          #\")\n",
        "    print(\"############################################################################################\")\n",
        "    print()\n",
        "\n",
        "    print(\"Parameter:\")\n",
        "    print(\"##########\")\n",
        "    print()\n",
        "    print(\"Modellnummer: \"+str(model_number))\n",
        "    print(\"Normalisierung: \"+str(normalizing_images))\n",
        "    print(\"Standardisierung: \"+str(standardizing_images))\n",
        "    print(\"Preprocessing: \"+str(preprocesing_images))\n",
        "    print(\"Bilder mit Sticker (rot, Aruco, etc.): \"+str(images_with_sticker))\n",
        "    print(\"Auflösung Breite: \"+str(widthquer))\n",
        "    print(\"Auflösung Höhe: \"+str(heightquer))\n",
        "    print(\"Synthetisch - gespiegelt: \"+str(synthetic_images_mirror))\n",
        "    print(\"Synthetisch - rotiert: \"+str(synthetic_images_rotation))\n",
        "    print(\"Synthetisch - Rauschen: \"+str(synthetic_images_noise))\n",
        "    print(\"Synthetisch - Helligkeit: \"+str(synthetic_images_brightness))\n",
        "    print(\"Synthetisch - Schärfe: \"+str(synthetic_images_sharpness))\n",
        "    print()\n",
        "\n",
        "\n",
        "    ##################################################################################\n",
        "    # Baustellen und Wand ID aus Dateinamen laden um Train/Testsplit auf Wandebene vorzubereiten\n",
        "    ##################################################################################\n",
        "    for filename in os.listdir(srcpath_images):\n",
        "        # Trennt den Filename in den reinen Filename und Extension\n",
        "        filenameshort, extension = os.path.splitext(filename)\n",
        "        # Prüft ob Datei .jpg ist\n",
        "        if extension == \".jpg\":\n",
        "            # Splitted den Dateinamen mit dem Trennoperator \"_\" und speichert den Inhalt in eine Liste\n",
        "            splittedfilename = filenameshort.split(\"_\")\n",
        "            # Speichert die Baustellennummer und Wandnummer zwischen\n",
        "            img_baustellenID = splittedfilename[1]\n",
        "            img_wandID = splittedfilename[2]\n",
        "            img_baustellenUndWandID = img_baustellenID+\"_\"+img_wandID\n",
        "            # Welche Images sollen aus dem vorher angegebenen SrcOrdner verwendet werden. Gefiltert wird nach den Flags im Dateinamen\n",
        "            if (check_ImageIsInFilter(splittedfilename, images_with_sticker, images_taken_with_DSLR, images_taken_with_Smartphone, \n",
        "                    images_taken_format_landscape, images_taken_format_portrait, synthetic_images_mirror, \n",
        "                    synthetic_images_rotation, synthetic_images_noise, synthetic_images_brightness, synthetic_images_sharpness)):\n",
        "                if img_baustellenUndWandID not in waende_alle:\n",
        "                    waende_alle.append(img_baustellenUndWandID)\n",
        "    waende_alle_count = len(waende_alle)  \n",
        "    print()\n",
        "    print(\"Einlesen der Daten:\")\n",
        "    print(\"###################\")\n",
        "    print()        \n",
        "    print(\"Anzahl aller verwendeten Wände/Szenen: \"+str(waende_alle_count))\n",
        "    # Bestimmt die Anzahl der Wände für den Trainingssplit. Dafür wird der vorherig definierte Faktor verwendet\n",
        "    waende_train, waende_val = train_test_split(waende_alle, train_size=faktorTrainSplit, random_state=42)\n",
        "    waende_train_count = len(waende_train)\n",
        "    print(\"Anzahl der Wände/Szenen für das Trainingset: \"+str(waende_train_count))\n",
        "    waende_val_count = len(waende_val)\n",
        "    print(\"Anzahl der Wände/Szenen für das Validationset: \"+str(waende_val_count))\n",
        "\n",
        "\n",
        "    ##################################################################################\n",
        "    # gewünschte Bilder werden bearbeitet und dem Train- oder Testsplit hinzugefügt\n",
        "    ##################################################################################\n",
        "    for filename in os.listdir(srcpath_images):\n",
        "        # Trennt den Filename in den reinen Filename und Extension\n",
        "        filenameshort, extension = os.path.splitext(filename)\n",
        "        # Prüft ob Datei .jpg ist\n",
        "        if extension == \".jpg\":\n",
        "            # Splitted den Dateinamen mit dem Trennoperator \"_\" und speichert den Inhalt in eine Liste\n",
        "            splittedfilename = filenameshort.split(\"_\")\n",
        "            # Speichert die Baustellennummer und Wandnummer zwischen\n",
        "            img_baustellenID = splittedfilename[1]\n",
        "            img_wandID = splittedfilename[2]\n",
        "            img_baustellenUndWandID = img_baustellenID+\"_\"+img_wandID\n",
        "            # Welche Images sollen aus dem vorher angegebenen Src-Ordner verwendet werden. \n",
        "            # Gefiltert wird nach den Flags im Dateinamen (siehe Methode \"check_ImageIsInFilter\")\n",
        "            if (check_ImageIsInFilter(splittedfilename, images_with_sticker, images_taken_with_DSLR, images_taken_with_Smartphone, \n",
        "                    images_taken_format_landscape, images_taken_format_portrait, synthetic_images_mirror, \n",
        "                    synthetic_images_rotation, synthetic_images_noise, synthetic_images_brightness, synthetic_images_sharpness)):\n",
        "                # Gefilterte Bilder/Images laden\n",
        "                #print(filename)\n",
        "                img = cv2.imread(os.path.join(srcpath_images,filename))\n",
        "\n",
        "\n",
        "                ###################################################################################\n",
        "                # Preprocessing1 der Bilder\n",
        "                ###################################################################################\n",
        "                if preprocesing_images == 1:\n",
        "                  imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #Bild wird schwarz weiß\n",
        "                  # print(f\"Shape imgGray: {imgGray.shape}\")\n",
        "                  imgBlur=cv2.GaussianBlur(imgGray,(5,5),1) #Kernel 5*5\n",
        "                  # print(f\"Shape imgBlur: {imgGray.shape}\")\n",
        "                  # Canny Filter: Thr = For this, we need two threshold values, minVal and maxVal. Any edges with intensity gradient more than maxVal are sure to be edges and those below minVal are sure to be non-edges, so discarded.\n",
        "                  imgCanny=cv2.Canny(imgBlur, 40, 40) #Cannyfilter (25, 25 guter Wert, wenn nur Canny)\n",
        "                  # print(f\"Shape imgCanny: {imgCanny.shape}\")\n",
        "                  kernel= np.ones((5,5)) #Neuer Kernel für Dilate (5*5 groß)\n",
        "                  imgDial = cv2.dilate(imgCanny,kernel,iterations=2) #Erweitert das Bild (verstärkt)\n",
        "                  # print(f\"Shape imgDial: {imgDial.shape}\")\n",
        "                  imgThre=cv2.erode(imgDial,kernel,iterations=1) #Verfeinert das Bild (verwässert)\n",
        "                  # print(f\"Shape imgThre: {imgThre.shape}\")\n",
        "                  img = imgThre\n",
        "\n",
        "\n",
        "                ##################################################################################\n",
        "                # Resizing der Bilder\n",
        "                ##################################################################################\n",
        "                if resizing_images == 1:\n",
        "                  # Resize der Bilder auf neue Maße wie zu Beginn angegeben\n",
        "                  # Prüft ob Bild Querformat ist\n",
        "                  if check_images_taken_format_landscape(splittedfilename):\n",
        "                      dim = (widthquer, heightquer)\n",
        "                  # Prüft ob Bild Hochformat ist\n",
        "                  elif check_images_taken_format_portrait(splittedfilename):\n",
        "                      dim = (widthhoch, heighthoch)\n",
        "                  # Resize mit neuen Dimensionen\n",
        "                  resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "                  img = resized\n",
        "\n",
        "\n",
        "                ###################################################################################\n",
        "                # Speichern der Bilder in die zuvor angegebenen Zielordner  \n",
        "                ###################################################################################\n",
        "                if saving_images_to_dir == 1:\n",
        "                  if img_baustellenUndWandID in waende_train:\n",
        "                      cv2.imwrite(os.path.join(destpath_train_images , filenameshort+'.jpg'),img)\n",
        "                  elif check_ImageIsOriginal(splittedfilename):\n",
        "                      cv2.imwrite(os.path.join(destpath_val_images , filenameshort+'.jpg'),img)\n",
        "\n",
        "\n",
        "                ###################################################################################\n",
        "                # Normalisierung\n",
        "                ###################################################################################\n",
        "                if normalizing_images == 1:\n",
        "                  img = img/255\n",
        "\n",
        "\n",
        "                ###################################################################################\n",
        "                # Standardisierung\n",
        "                ###################################################################################\n",
        "                if standardizing_images == 1:\n",
        "                  img = np.array(img, dtype=np.int64)\n",
        "                  imgst = (img - np.mean(img)) / np.std(img)\n",
        "                  img = imgst\n",
        "\n",
        "\n",
        "                ###################################################################################\n",
        "                # Preprocessing2 der Bilder \n",
        "                ###################################################################################\n",
        "                # (S/W Bilder haben weniger Dimensionen als Bilder in Farbe, weshalb weitere hinzugefügt werden)\n",
        "                if preprocesing_images == 1:\n",
        "                  # print(f\"Shape before new dimension: {img.shape}\")\n",
        "                  img = tf.expand_dims(img,axis=2)\n",
        "                  # print(f\"Shape after new dimension: {img.shape}\")\n",
        "\n",
        "\n",
        "                ##################################################################################\n",
        "                # Speichern der Bilder und der zugehörigen Labels in die Arrays des Train- und Testsets  \n",
        "                ################################################################################## \n",
        "                # Prüft ob das Bild zu den Traingswänden gehört\n",
        "                if img_baustellenUndWandID in waende_train:\n",
        "                    x_train_material.append(np.array(img))\n",
        "                    # Iteriert durch die Infos aus der CSV und schaut ob die BaustellenID und WandID der Dateien mit den Zeilen in der CSV matchen. Falls ja, dann soll das zugehörige \n",
        "                    # Label in das Array \"y_train_material\" gespeichert werden. \n",
        "                    for i in range(len(wand_label_info)):\n",
        "                        # Prüft ob BaustellenID und WandID mit den Spalten in der CSV übereinstimmen.\n",
        "                        if (\n",
        "                            str(wand_label_info[i][0]) == img_baustellenID and\n",
        "                            str(wand_label_info[i][1]) == img_wandID\n",
        "                        ):\n",
        "                            # Fügt den Wert der gewählten Spalte in der CSV dem Array \"y_train_material\" hinzu\n",
        "                            y_train_material.append(np.array(wand_label_info[i][csv_spalte_labelinfo]))\n",
        "                    # Den Dateinamen des gefilterten Traings-Images in einem Array speichern. Für spätere Kontrolle nützlich\n",
        "                    images_train_filenames.append(filename)\n",
        "                    # Den Dateinamen des gefilterten Images in einem Array speichern in dem alle verwendeten Dateinamen gespeichert werden. Für spätere Kontrolle nützlich\n",
        "                    images_all_filenames.append(filename)\n",
        "                # Prüft ob das Bild zu den Validationwänden gehört, dabei werden nur Originalbilder dem Validationsplit hinzugefügt\n",
        "                elif check_ImageIsOriginal(splittedfilename):\n",
        "                    x_val_material.append(np.array(img))\n",
        "                    # Iteriert durch die Infos aus der CSV und schaut ob die BaustellenID und WandID der Dateien mit den Zeilen in der CSV matchen. Falls ja, dann soll das zugehörige \n",
        "                    # Label in das Array \"y_val_material\" gespeichert werden. \n",
        "                    for i in range(len(wand_label_info)):\n",
        "                        # Prüft ob BaustellenID und WandID mit den Spalten in der CSV übereinstimmen.\n",
        "                        if (\n",
        "                            str(wand_label_info[i][0]) == img_baustellenID and\n",
        "                            str(wand_label_info[i][1]) == img_wandID\n",
        "                        ):\n",
        "                            # Fügt den Wert der gewählten Spalte in der CSV dem Array \"y_train_material\" hinzu\n",
        "                            y_val_material.append(np.array(wand_label_info[i][csv_spalte_labelinfo]))\n",
        "                    # Den Dateinamen des gefilterten Traings-Images in einem Array speichern. Für spätere Kontrolle nützlich\n",
        "                    images_val_filenames.append(filename)\n",
        "                    # Den Dateinamen des gefilterten Images in einem Array speichern in dem alle verwendeten Dateinamen gespeichert werden. Für spätere Kontrolle nützlich\n",
        "                    images_all_filenames.append(filename)\n",
        "\n",
        "\n",
        "    ##################################################################################\n",
        "    # Konvertierung in NP Arrays\n",
        "    ################################################################################## \n",
        "    images_train_filename = np.array(images_train_filenames)\n",
        "    images_val_filename = np.array(images_val_filenames)\n",
        "    images_all_filenames = np.array(images_all_filenames)\n",
        "    x_train_material = np.array(x_train_material)\n",
        "    y_train_material = np.array(y_train_material)\n",
        "    x_val_material = np.array(x_val_material)\n",
        "    y_val_material = np.array(y_val_material)\n",
        "\n",
        "\n",
        "    ##################################################################################\n",
        "    # Ausgabe der Werte auf der Konsole\n",
        "    ################################################################################## \n",
        "    print()\n",
        "    images_all_count = len(images_all_filenames)\n",
        "    print(\"Anzahl aller verwendeter Bilder: \"+str(images_all_count))\n",
        "    print()\n",
        "\n",
        "    print(\"Traingset:\")\n",
        "    x_train_images_count = len(x_train_material)\n",
        "    print(\"Anzahl der im Array x_train_material gespeicherten Bilder: \"+str(x_train_images_count))\n",
        "    y_train_material_labelcount = len(y_train_material)\n",
        "    print(\"Anzahl der im Array y_train_material gespeicherten Labels: \"+str(y_train_material_labelcount))\n",
        "    y_train_material_min = np.amin(y_train_material)\n",
        "    print(\"y_train_material Min: \"+str(y_train_material_min))\n",
        "    y_train_material_max = np.amax(y_train_material)\n",
        "    print(\"y_train_material Max: \"+str(y_train_material_max))\n",
        "    y_train_material_mean = round(np.mean(y_train_material))\n",
        "    print(\"y_train_material Mean: \"+str(y_train_material_mean))\n",
        "    print()\n",
        "\n",
        "    print(\"Validationset:\")\n",
        "    x_val_images_count = len(x_val_material)\n",
        "    print(\"Anzahl der im Array x_val_material gespeicherten Bilder: \"+str(x_val_images_count))\n",
        "    y_val_material_labelcount = len(y_val_material)\n",
        "    print(\"Anzahl der im Array y_val_material gespeicherten Labels: \"+str(y_val_material_labelcount))\n",
        "    y_val_material_min = np.amin(y_val_material)\n",
        "    print(\"y_val_material Min: \"+str(y_val_material_min))\n",
        "    y_val_material_max = np.amax(y_val_material)\n",
        "    print(\"y_val_material Max: \"+str(y_val_material_max))\n",
        "    y_val_material_mean = round(np.mean(y_val_material))\n",
        "    print(\"y_val_material Mean: \"+str(y_val_material_mean))\n",
        "    print()\n",
        "\n",
        "\n",
        "    ##################################################################################\n",
        "    # Definieren des Modells\n",
        "    ##################################################################################  \n",
        "\n",
        "    if preprocesing_images == 1:\n",
        "      # Wenn Preproccessng genutzt wird ist das Bild schwarz/weiß. Dadurch hat das Bild nur eine Tiefe von einer Schicht.\n",
        "      image_layer = 1\n",
        "    else:\n",
        "      # Falls kein Preproccessing genutzt wird ist das Bild in Farbe. Dadurch hat das Bild eine Tiefe von drei Schichten.\n",
        "      image_layer = 3\n",
        "\n",
        "    print()\n",
        "    print(\"Definieren des Modells:\")\n",
        "    print(\"#######################\")\n",
        "    print()\n",
        "    # Welches Modell gewählt wird, wird über einen Trainingsparameter gesteuert.\n",
        "    if model_number == 1:\n",
        "        print(\"Modell 1 gewählt\")\n",
        "        tf.keras.backend.clear_session()\n",
        "        material_model = Sequential([\n",
        "            Conv2D(128, kernel_size=3, activation='relu', input_shape=(heightquer, widthquer, image_layer)),\n",
        "            MaxPool2D(pool_size=3, strides=2),\n",
        "            Conv2D(128, kernel_size=3, activation='relu'),\n",
        "            MaxPool2D(pool_size=3, strides=2),\n",
        "            Conv2D(256, kernel_size=3, activation='relu'),\n",
        "            MaxPool2D(pool_size=3, strides=2),\n",
        "            Conv2D (512, kernel_size=3, activation='relu'),\n",
        "            MaxPool2D(pool_size=3, strides=2),\n",
        "            Flatten(),\n",
        "            Dropout(0.5),\n",
        "            Dense(512, activation='relu'),\n",
        "            Dense(1, activation='linear', name='material')\n",
        "        ])\n",
        "    elif model_number == 2:\n",
        "        print(\"Modell 2 gewählt\")\n",
        "        tf.keras.backend.clear_session()\n",
        "        material_model = Sequential([\n",
        "            Conv2D(128, kernel_size=3, activation='relu', input_shape=(heightquer, widthquer, image_layer)),\n",
        "            MaxPool2D(pool_size=3, strides=2),\n",
        "            Conv2D(256, kernel_size=3, activation='relu'),\n",
        "            MaxPool2D(pool_size=3, strides=2),\n",
        "            Conv2D(512, kernel_size=3, activation='relu'),\n",
        "            MaxPool2D(pool_size=3, strides=2),\n",
        "            Conv2D(1024, kernel_size=3, activation='relu'),\n",
        "            MaxPool2D(pool_size=3, strides=2),\n",
        "            Flatten(),\n",
        "            Dropout(0.5),\n",
        "            Dense(1024, activation='relu'),\n",
        "            Dense(1, activation='linear', name='material')\n",
        "        ])\n",
        "    elif model_number == 3:\n",
        "        print(\"Modell 3 gewählt\")\n",
        "        tf.keras.backend.clear_session()\n",
        "        material_model = Sequential([\n",
        "            Conv2D(128, kernel_size=3, activation='relu', input_shape=(heightquer, widthquer, image_layer)),\n",
        "            MaxPool2D(pool_size=3, strides=2),\n",
        "            Conv2D(128, kernel_size=3, activation='relu'),\n",
        "            MaxPool2D(pool_size=3, strides=2),\n",
        "            Conv2D(256, kernel_size=3, activation='relu'),\n",
        "            MaxPool2D(pool_size=3, strides=2),\n",
        "            Conv2D(256, kernel_size=3, activation='relu'),\n",
        "            MaxPool2D(pool_size=3, strides=2),\n",
        "            Conv2D(512, kernel_size=3, activation='relu'),\n",
        "            MaxPool2D(pool_size=3, strides=2),\n",
        "            Flatten(),\n",
        "            Dropout(0.5),\n",
        "            Dense(512, activation='relu'),\n",
        "            Dense(1, activation='linear', name='material')\n",
        "        ])\n",
        "    elif model_number == 4:\n",
        "        print(\"Modell 4 gewählt\")\n",
        "        tf.keras.backend.clear_session()\n",
        "        material_model = Sequential([\n",
        "            Conv2D(128, kernel_size=3, activation='relu', input_shape=(heightquer, widthquer, image_layer)),\n",
        "            MaxPool2D(pool_size=3, strides=2),\n",
        "            Conv2D(128, kernel_size=3, activation='relu'),\n",
        "            MaxPool2D(pool_size=3, strides=2),\n",
        "            Conv2D(256, kernel_size=3, activation='relu'),\n",
        "            MaxPool2D(pool_size=3, strides=2),\n",
        "            Conv2D(512, kernel_size=3, activation='relu'),\n",
        "            MaxPool2D(pool_size=3, strides=2),\n",
        "            Conv2D(1024, kernel_size=3, activation='relu'),\n",
        "            MaxPool2D(pool_size=3, strides=2),\n",
        "            Flatten(),\n",
        "            Dropout(0.5),\n",
        "            Dense(1024, activation='relu'),\n",
        "            Dense(1, activation='linear', name='material')\n",
        "        ])\n",
        "    else:\n",
        "        print(\"Modell 5 gewählt\")\n",
        "        tf.keras.backend.clear_session()\n",
        "        material_model = Sequential([\n",
        "            Conv2D(128, kernel_size=5, strides=2, activation='relu', input_shape=(heightquer, widthquer, image_layer)),\n",
        "            MaxPool2D(pool_size=3, strides=2),\n",
        "            Conv2D(256, kernel_size=5, strides=2, activation='relu'),\n",
        "            MaxPool2D(pool_size=3, strides=2),\n",
        "            Conv2D(512, kernel_size=3, strides=2, activation='relu'),\n",
        "            MaxPool2D(pool_size=3, strides=2),\n",
        "            Flatten(),\n",
        "            Dropout(0.5),\n",
        "            Dense(512, activation='relu'),\n",
        "            Dense(1, activation='linear', name='material')\n",
        "        ])\n",
        "\n",
        "    material_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mse',\n",
        "    metrics =['mae']\n",
        "    )\n",
        "\n",
        "    # Legt den CSV Callback für die History an\n",
        "    my_callbacks = [\n",
        "        tf.keras.callbacks.CSVLogger((destpath_logsave + \"Training_History.csv\"), separator=';', append=False)\n",
        "    ]\n",
        "\n",
        "    # Nullt die Variable für die Größe des Modells\n",
        "    modelsize = 0\n",
        "    # Speichert die Anzahl der Modell-Parameter in Variablen für die finale Evaluation\n",
        "    model_trainable_parameter_count = count_params(material_model.trainable_weights)\n",
        "    model_non_trainable_parameter_count = count_params(material_model.non_trainable_weights)\n",
        "    model_parameter_total_count = model_trainable_parameter_count + model_non_trainable_parameter_count\n",
        "\n",
        "\n",
        "    ##################################################################################\n",
        "    # Printen des Modells\n",
        "    ################################################################################## \n",
        "    print()\n",
        "    print()\n",
        "    print(\"Printen des Modells:\")\n",
        "    print(\"####################\")\n",
        "    print()\n",
        "    print(material_model.summary ())\n",
        "    print()\n",
        "\n",
        "\n",
        "    ##################################################################################\n",
        "    # Training des Modells\n",
        "    ################################################################################## \n",
        "    print()\n",
        "    print(\"Trainieren des Modells:\")\n",
        "    print(\"#######################\")\n",
        "    print()\n",
        "    training_material = material_model.fit(x=x_train_material, y=y_train_material, \n",
        "    validation_data=(x_val_material, y_val_material), batch_size=32, shuffle=True, \n",
        "    epochs=epochs_train, callbacks=my_callbacks)\n",
        "    print()\n",
        "\n",
        "\n",
        "    ##################################################################################\n",
        "    # Ausgabe auf der Konsole\n",
        "    ################################################################################## \n",
        "    print()\n",
        "    print(\"History und Logfiles:\")\n",
        "    print(\"#####################\")\n",
        "\n",
        "\n",
        "    ##################################################################################\n",
        "    # Finales speichern des Modells\n",
        "    ################################################################################## \n",
        "    # Speichert die Modelle in der definierten Ordnerstuktur ab\n",
        "    if saving_model_to_dir == 1:\n",
        "        destpath_model = destpath_modelsave + \"material_model_final.h5\"\n",
        "        material_model.save(destpath_model)\n",
        "        modelsize = os.path.getsize(destpath_model)\n",
        "        modelsize = modelsize / 1048576\n",
        "        modelsize = round(modelsize, 2)\n",
        "        print()\n",
        "        print(\"- Final trainiertes Modell wurde gespeichert\")\n",
        "\n",
        "\n",
        "    ##################################################################################\n",
        "    # Plotten und Speichern der Trainings-History des Modells\n",
        "    ################################################################################## \n",
        "\n",
        "    plt.plot(training_material.history['mae'])\n",
        "    plt.plot(training_material.history['val_mae'])\n",
        "    plt.title('Abweichung')\n",
        "    plt.ylabel('MAE')\n",
        "    plt.xlabel('Epoche')\n",
        "    plt.legend(['Training', 'Validierung'], loc='upper right')\n",
        "    plt.savefig(destpath_plotsave +\"Training\"+str(training_number)+ '_mae_vs_val_mae.png')\n",
        "    plt.savefig(destpath_batchplots +\"Training\"+str(training_number)+ '_mae_vs_val_mae.png')\n",
        "    #plt.show()\n",
        "    plt.clf()\n",
        "\n",
        "    plt.plot(training_material.history['loss'])\n",
        "    plt.plot(training_material.history['val_loss'])\n",
        "    plt.title('Quadratische Abweichung')\n",
        "    plt.ylabel('MSE')\n",
        "    plt.xlabel('Epoche')\n",
        "    plt.legend(['Training', 'Validierung'], loc='upper right')\n",
        "    plt.savefig(destpath_plotsave +\"Training\"+str(training_number)+ '_mse_vs_val_mse.png')\n",
        "    plt.savefig(destpath_batchplots +\"Training\"+str(training_number)+ '_mse_vs_val_mse.png')\n",
        "    #plt.show()\n",
        "    plt.clf()\n",
        "    \n",
        "    print(\"- Plots des Modells wurden gespeichert\")\n",
        "\n",
        "    ##################################################################################\n",
        "    # Evaluieren der einzelnen Bilder des Trainingsplit per predict\n",
        "    ##################################################################################\n",
        "    # Für die Kontrolle einzelner Ergebnisse, werden alle Bilder des Trainingsplits\n",
        "    # einzeln per predict Befehl evaluiert und in eine CSV exportiert.\n",
        "    i = 0\n",
        "    evaluation_train = []\n",
        "    while i < len(x_train_material):\n",
        "\n",
        "      x = x_train_material[i]\n",
        "      x = tf.expand_dims(x,axis=0)\n",
        "      actual_need = y_train_material[i]\n",
        "      result = material_model.predict(x)\n",
        "      result = round(result[0][0])\n",
        "      deviation = abs(actual_need-result)\n",
        "\n",
        "      row = []\n",
        "      row.append(images_train_filenames[i])\n",
        "      row.append(actual_need)\n",
        "      row.append(result)\n",
        "      row.append(deviation)\n",
        "\n",
        "      evaluation_train.append(row)\n",
        "      i += 1\n",
        "\n",
        "    evaluation_train = sorted(evaluation_train, key=lambda x:x[3])\n",
        "\n",
        "    with open(destpath_logsave + \"Evaluation_Train.csv\", 'w', newline='', encoding='utf-8-sig') as f_object:  \n",
        "        writer_object = writer(f_object, delimiter=\";\")\n",
        "        writer_object.writerow([\"Dateiname\", \"Tatsächlicher Materialbedarf in g\", \"geschätzer Materialbedarf in g\", \"Abweichung Materialbedarf in g\"])\n",
        "        writer_object.writerows(evaluation_train)  \n",
        "        f_object.close()\n",
        "\n",
        "    print(\"- Evaluieren der einzelnen Bilder des Trainingsplit per predict wurde durchgeführt\")\n",
        "\n",
        "\n",
        "\n",
        "    ##################################################################################\n",
        "    # Evaluieren der einzelnen Bilder des Validationsplit per predict\n",
        "    ##################################################################################\n",
        "    # Für die Kontrolle einzelner Ergebnisse, werden alle Bilder des Validationsplits\n",
        "    # einzeln per predict Befehl evaluiert und in eine CSV exportiert.\n",
        "    i = 0\n",
        "    evaluation_val = []\n",
        "    while i < len(x_val_material):\n",
        "\n",
        "      x = x_val_material[i]\n",
        "      x = tf.expand_dims(x,axis=0)\n",
        "      actual_need = y_val_material[i]\n",
        "      result = material_model.predict(x)\n",
        "      result = round(result[0][0])\n",
        "      deviation = abs(actual_need-result)\n",
        "\n",
        "      row = []\n",
        "      row.append(images_val_filenames[i])\n",
        "      row.append(actual_need)\n",
        "      row.append(result)\n",
        "      row.append(deviation)\n",
        "\n",
        "      evaluation_val.append(row)\n",
        "      i += 1\n",
        "\n",
        "    evaluation_val = sorted(evaluation_val, key=lambda x:x[3])\n",
        "\n",
        "    with open(destpath_logsave + \"Evaluation_Validation.csv\", 'w', newline='', encoding='utf-8-sig') as f_object:  \n",
        "        writer_object = writer(f_object, delimiter=\";\")\n",
        "        writer_object.writerow([\"Dateiname\", \"Tatsächlicher Materialbedarf in g\", \"geschätzer Materialbedarf in g\", \"Abweichung Materialbedarf in g\"])\n",
        "        writer_object.writerows(evaluation_val)  \n",
        "        f_object.close()\n",
        "\n",
        "\n",
        "    print(\"- Evaluieren der einzelnen Bilder des Validationsplit per predict wurde durchgeführt\")\n",
        "\n",
        "\n",
        "\n",
        "    ##################################################################################\n",
        "    # Evaluieren des Modells \n",
        "    ##################################################################################\n",
        "    # Erzeugt einen Eintrag mit den Trainingsparametern und -ergebnissen in der \n",
        "    # Evaluation_Output.csv\n",
        "\n",
        "    y_train_material_mae = round(training_material.history['mae'][-1])\n",
        "    y_train_material_share = round((y_train_material_mae / y_train_material_mean), 3)\n",
        "    y_val_material_mae = round(training_material.history['val_mae'][-1])\n",
        "    y_val_material_share = round((y_val_material_mae / y_val_material_mean), 3)\n",
        "    train_val_share = round((y_val_material_share - y_train_material_share), 3)\n",
        "    model_numbername = \"Modell \" + str(model_number)\n",
        "    trainingcount = \"Training \" + str(training_number)\n",
        "    images_format = str(widthquer) + \"x\" + str(heightquer)  \n",
        "\n",
        "    # Erzeugt eine Liste mit den Variablen die in die Evaluation_Output.csv zurückgeschrieben werden.\n",
        "    # Eine Beschreibung der Variablen erfolgt weiter unten im Code.\n",
        "    var_list = [\n",
        "        date_of_training, \n",
        "        time_of_training, \n",
        "        model_numbername,\n",
        "        trainingcount, \n",
        "        model_parameter_total_count, \n",
        "        modelsize, \n",
        "        epochs_train, \n",
        "        normalizing_images, \n",
        "        standardizing_images, \n",
        "        preprocesing_images,\n",
        "        synthetic_images_mirror,\n",
        "        synthetic_images_rotation,\n",
        "        synthetic_images_noise,\n",
        "        synthetic_images_brightness,\n",
        "        synthetic_images_sharpness,\n",
        "        images_with_sticker,\n",
        "        waende_alle_count,\n",
        "        waende_train_count,\n",
        "        waende_val_count, \n",
        "        images_all_count, \n",
        "        x_train_images_count, \n",
        "        x_val_images_count, \n",
        "        images_format,\n",
        "        y_train_material_mean, \n",
        "        y_train_material_mae, \n",
        "        y_train_material_share, \n",
        "        y_val_material_mean, \n",
        "        y_val_material_mae, \n",
        "        y_val_material_share, \n",
        "        train_val_share\n",
        "    ]\n",
        "\n",
        "    if os.path.exists(evalpath_output) == False:\n",
        "      with open(evalpath_output, 'w', newline='', encoding='utf-8-sig') as f_object:\n",
        "        writer_object = writer(f_object, delimiter=\";\")\n",
        "        writer_object.writerow([\"Trainingsdatum\", \n",
        "                                \"Trainingszeitpunkt\",\n",
        "                                \"Modellnummer\",\n",
        "                                \"Trainingsnummer\", \n",
        "                                \"Anzahl der Parameter des Modells\", \n",
        "                                \"Modellgröße in MB\", \n",
        "                                \"Trainierte Epochen\",\n",
        "                                \"Normalisierung\", \n",
        "                                \"Standardisierung\", \n",
        "                                \"Preprocessing\",\n",
        "                                \"Synthetisch - gespiegelt\",\n",
        "                                \"Synthetisch - rotiert\",\n",
        "                                \"Synthetisch - Rauschen\",\n",
        "                                \"Synthetisch - Helligkeit\",\n",
        "                                \"Synthetisch - Schärfe\",\n",
        "                                \"Bilder mit Sticker (rot, Aruco)\",\n",
        "                                \"Anzahl aller Wände/Szenen\", \n",
        "                                \"Wände Trainingsplit\", \n",
        "                                \"Wände Validationsplit\", \n",
        "                                \"Anzahl aller Bilder\", \n",
        "                                \"Bilder Trainingsplit\", \n",
        "                                \"Bilder Validationsplit\", \n",
        "                                \"Auflösung der Bilder\",\n",
        "                                \"Mean Trainingsplit Spachtelmasse\", \n",
        "                                \"Mae Trainingsplit Spachtelmasse\", \n",
        "                                \"Mae/Mean Verhältnis Trainingsplit Spachtelmasse in %\", \n",
        "                                \"Mean Validationsplit Spachtelmasse\",\n",
        "                                \"Mae Validationplit Spachtelmasse\", \n",
        "                                \"Mae/Mean Verhältnis Validationsplit Spachtelmasse in %\",\n",
        "                                \"Mae Verhältnis Trainings/Validationsplit Spachtelmasse in %\" \n",
        "                                ])\n",
        "\n",
        "    with open(evalpath_output, 'a', newline='', encoding='utf-8-sig') as f_object:  \n",
        "      writer_object = writer(f_object, delimiter=\";\")\n",
        "      writer_object.writerow(var_list)  \n",
        "      f_object.close()\n",
        "\n",
        "\n",
        "    print(\"- Allgemeines evaluieren des Modells wurde durchgeführt\")\n",
        "    print()\n",
        "    print()\n",
        "    print()\n",
        "    print()\n",
        "\n",
        "    #Delete Model / Clear session\n",
        "    K.clear_session()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMeUYnDrYgEh"
      },
      "source": [
        "Mit dieser Zelle wird ein Teilautomatisiertes Training gestartet. Dabei wird im Vorfeld eine Evaluation_Input.csv eingelesen. Die Evaluation_Input.csv muss mindestens zwei Trainingszeilen enthalten. Über die Evaluation_Input.csv werden einzelne Trainingsparameter übergeben. Zusätzlich können einzelne Parameter in der Zelle definiert werden. Der Code ist entsprechend kommentiert. Nach dem Einlesen der Evaluation_Input.csv wird die Methode *doTrainingwithParameters* für jede Zeile der Datei aufgerufen und ein Training durchgeführt. Nach jedem Training werden Trainingsergebnisse und -paramter an die Evaluation_Output.csv angehängt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_ukpjONhM0cv",
        "outputId": "1ed7e4f0-2f79-44bf-f4ad-62d2dd734aa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[[  1   0   0   0   1 200 150   0   0   0   0   0]\n",
            " [  1   0   0   0   0 400 300   0   0   0   0   0]]\n",
            "\n",
            "############################################################################################\n",
            "#                                                                                          #\n",
            "#                                  Training 1                                             #\n",
            "#                                                                                          #\n",
            "############################################################################################\n",
            "\n",
            "Parameter:\n",
            "##########\n",
            "\n",
            "Modellnummer: 1\n",
            "Normalisierung: 0\n",
            "Standardisierung: 0\n",
            "Preprocessing: 0\n",
            "Bilder mit Sticker (rot, Aruco, etc.): 1\n",
            "Auflösung Breite: 200\n",
            "Auflösung Höhe: 150\n",
            "Synthetisch - gespiegelt: 0\n",
            "Synthetisch - rotiert: 0\n",
            "Synthetisch - Rauschen: 0\n",
            "Synthetisch - Helligkeit: 0\n",
            "Synthetisch - Schärfe: 0\n",
            "\n",
            "\n",
            "Einlesen der Daten:\n",
            "###################\n",
            "\n",
            "Anzahl aller verwendeten Wände/Szenen: 114\n",
            "Anzahl der Wände/Szenen für das Trainingset: 91\n",
            "Anzahl der Wände/Szenen für das Validationset: 23\n",
            "\n",
            "Anzahl aller verwendeter Bilder: 565\n",
            "\n",
            "Traingset:\n",
            "Anzahl der im Array x_train_material gespeicherten Bilder: 487\n",
            "Anzahl der im Array y_train_material gespeicherten Labels: 487\n",
            "y_train_material Min: 2069\n",
            "y_train_material Max: 14992\n",
            "y_train_material Mean: 6501\n",
            "\n",
            "Validationset:\n",
            "Anzahl der im Array x_val_material gespeicherten Bilder: 78\n",
            "Anzahl der im Array y_val_material gespeicherten Labels: 78\n",
            "y_val_material Min: 1688\n",
            "y_val_material Max: 12008\n",
            "y_val_material Mean: 7352\n",
            "\n",
            "\n",
            "Definieren des Modells:\n",
            "#######################\n",
            "\n",
            "Modell 1 gewählt\n",
            "\n",
            "\n",
            "Printen des Modells:\n",
            "####################\n",
            "\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 198, 128)     3584      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 73, 98, 128)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 71, 96, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 35, 47, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 33, 45, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 22, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 14, 20, 512)       1180160   \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 6, 9, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 27648)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 27648)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               14156288  \n",
            "                                                                 \n",
            " material (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,783,297\n",
            "Trainable params: 15,783,297\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "\n",
            "Trainieren des Modells:\n",
            "#######################\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 98624104.0000 - mae: 7089.1636 - val_loss: 8854887.0000 - val_mae: 2450.2739\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 2s 102ms/step - loss: 10116023.0000 - mae: 2629.2708 - val_loss: 9595925.0000 - val_mae: 2606.9067\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 9993069.0000 - mae: 2553.0869 - val_loss: 7868120.0000 - val_mae: 2255.0657\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 2s 106ms/step - loss: 8098390.5000 - mae: 2297.1423 - val_loss: 7467192.5000 - val_mae: 2229.0637\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 2s 106ms/step - loss: 8573517.0000 - mae: 2378.9272 - val_loss: 10222131.0000 - val_mae: 2708.9294\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 2s 106ms/step - loss: 8382351.5000 - mae: 2351.8743 - val_loss: 7064169.0000 - val_mae: 2139.0012\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 2s 106ms/step - loss: 7733323.5000 - mae: 2261.4905 - val_loss: 7335447.0000 - val_mae: 2213.6580\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 2s 103ms/step - loss: 7537789.5000 - mae: 2222.2471 - val_loss: 7575335.5000 - val_mae: 2282.0256\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 2s 103ms/step - loss: 8354742.0000 - mae: 2317.8862 - val_loss: 6586261.5000 - val_mae: 2039.3129\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 2s 103ms/step - loss: 7076019.5000 - mae: 2171.9556 - val_loss: 6857352.5000 - val_mae: 2208.2080\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 6770541.5000 - mae: 2120.7766 - val_loss: 9438522.0000 - val_mae: 2699.8633\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 2s 103ms/step - loss: 6511998.5000 - mae: 2040.8278 - val_loss: 3569632.5000 - val_mae: 1551.7428\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 2s 107ms/step - loss: 5487146.5000 - mae: 1874.6157 - val_loss: 6627881.5000 - val_mae: 2308.8625\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 2s 103ms/step - loss: 5172977.5000 - mae: 1808.6395 - val_loss: 3070957.0000 - val_mae: 1440.0782\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 4798783.5000 - mae: 1726.7740 - val_loss: 5212797.5000 - val_mae: 1758.9244\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 4674590.0000 - mae: 1741.3531 - val_loss: 2306431.5000 - val_mae: 1128.9434\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 2s 107ms/step - loss: 4815081.5000 - mae: 1676.3459 - val_loss: 5904481.5000 - val_mae: 1994.3010\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 4266393.0000 - mae: 1647.4851 - val_loss: 2147388.5000 - val_mae: 1096.8862\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 3619379.2500 - mae: 1444.0791 - val_loss: 1973081.8750 - val_mae: 1101.9362\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 2855293.7500 - mae: 1339.2460 - val_loss: 3086087.5000 - val_mae: 1433.6124\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 2s 111ms/step - loss: 3214309.7500 - mae: 1433.5259 - val_loss: 2063141.7500 - val_mae: 1075.6337\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 2s 111ms/step - loss: 2816542.2500 - mae: 1322.2517 - val_loss: 2126274.7500 - val_mae: 1186.6519\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 2554009.7500 - mae: 1249.3396 - val_loss: 2028745.2500 - val_mae: 1123.5807\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 2543381.5000 - mae: 1250.0022 - val_loss: 2542867.2500 - val_mae: 1319.1375\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 2352986.2500 - mae: 1199.2856 - val_loss: 4332637.5000 - val_mae: 1791.5859\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 2s 108ms/step - loss: 2497068.7500 - mae: 1215.6156 - val_loss: 2874100.0000 - val_mae: 1402.2631\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 2155927.2500 - mae: 1156.2736 - val_loss: 1994436.2500 - val_mae: 1046.5979\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 2s 108ms/step - loss: 2176607.0000 - mae: 1154.3531 - val_loss: 2635876.5000 - val_mae: 1232.6096\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 1938840.6250 - mae: 1111.1343 - val_loss: 1957025.2500 - val_mae: 1072.8385\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 2015890.1250 - mae: 1076.0133 - val_loss: 2508702.0000 - val_mae: 1257.3920\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 2s 108ms/step - loss: 1735778.1250 - mae: 1034.5236 - val_loss: 2088479.1250 - val_mae: 1172.8865\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 1793404.7500 - mae: 1028.7875 - val_loss: 2579562.5000 - val_mae: 1206.9641\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 2s 108ms/step - loss: 1767294.6250 - mae: 1008.6298 - val_loss: 2184878.0000 - val_mae: 1160.5524\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 1794926.7500 - mae: 1043.4319 - val_loss: 2340905.2500 - val_mae: 1154.8773\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 1764078.3750 - mae: 1030.1023 - val_loss: 2075171.7500 - val_mae: 1114.6263\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 1335953.5000 - mae: 884.4222 - val_loss: 2282737.0000 - val_mae: 1179.1794\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 2s 108ms/step - loss: 1360760.0000 - mae: 916.2975 - val_loss: 2365222.0000 - val_mae: 1246.7732\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 1148701.6250 - mae: 820.3593 - val_loss: 2197591.7500 - val_mae: 1218.8438\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 2s 108ms/step - loss: 1191746.2500 - mae: 831.4268 - val_loss: 2288501.7500 - val_mae: 1236.7686\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 1121337.8750 - mae: 814.1478 - val_loss: 2617338.5000 - val_mae: 1351.2058\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 1159137.7500 - mae: 847.4742 - val_loss: 2102485.2500 - val_mae: 1129.2189\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 1054955.3750 - mae: 800.8795 - val_loss: 2299783.5000 - val_mae: 1189.4166\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 2s 107ms/step - loss: 1123871.7500 - mae: 789.6444 - val_loss: 2964623.0000 - val_mae: 1394.6675\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 1077974.3750 - mae: 803.3454 - val_loss: 2850368.5000 - val_mae: 1326.2946\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 1025033.0625 - mae: 759.9338 - val_loss: 3120878.7500 - val_mae: 1539.0763\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 1338614.3750 - mae: 859.9438 - val_loss: 2685022.2500 - val_mae: 1261.4015\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 1076989.6250 - mae: 797.0230 - val_loss: 2410999.5000 - val_mae: 1249.7352\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 1049687.6250 - mae: 779.6895 - val_loss: 2404560.5000 - val_mae: 1246.7190\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 940220.1875 - mae: 758.4973 - val_loss: 2341122.7500 - val_mae: 1176.9760\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 948882.1875 - mae: 750.0461 - val_loss: 2816848.0000 - val_mae: 1303.7815\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 1083219.7500 - mae: 830.3788 - val_loss: 2861069.7500 - val_mae: 1369.6797\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 845285.8125 - mae: 701.7803 - val_loss: 2740182.5000 - val_mae: 1411.1461\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 867030.1875 - mae: 720.3197 - val_loss: 2656552.0000 - val_mae: 1284.4492\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 948932.4375 - mae: 744.7662 - val_loss: 3138215.0000 - val_mae: 1450.5254\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 943553.3750 - mae: 739.0867 - val_loss: 2962951.5000 - val_mae: 1371.4825\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 846782.6875 - mae: 703.1736 - val_loss: 2884989.5000 - val_mae: 1372.1777\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 632866.2500 - mae: 616.4968 - val_loss: 2628076.7500 - val_mae: 1379.5371\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 2s 108ms/step - loss: 710760.5625 - mae: 637.4457 - val_loss: 2464918.2500 - val_mae: 1321.4633\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 820758.1250 - mae: 680.7504 - val_loss: 2691411.7500 - val_mae: 1387.6464\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 711510.5625 - mae: 636.6783 - val_loss: 2733439.0000 - val_mae: 1308.2345\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 844518.9375 - mae: 682.1683 - val_loss: 2571766.0000 - val_mae: 1297.0551\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 2s 108ms/step - loss: 845339.8750 - mae: 708.1961 - val_loss: 3989565.5000 - val_mae: 1668.7437\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 786928.7500 - mae: 678.5766 - val_loss: 2906810.5000 - val_mae: 1376.3253\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 2s 108ms/step - loss: 668023.5625 - mae: 615.7119 - val_loss: 2704229.7500 - val_mae: 1337.0648\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 2s 107ms/step - loss: 670202.5625 - mae: 632.8279 - val_loss: 2944328.2500 - val_mae: 1465.5006\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 703408.8750 - mae: 641.8718 - val_loss: 2128988.0000 - val_mae: 1163.2782\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 721751.0625 - mae: 641.7632 - val_loss: 2861426.7500 - val_mae: 1435.9817\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 2s 108ms/step - loss: 636857.3750 - mae: 610.3195 - val_loss: 2583543.0000 - val_mae: 1338.3143\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 719509.5000 - mae: 640.2714 - val_loss: 2855843.0000 - val_mae: 1303.8420\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 937706.0000 - mae: 751.7971 - val_loss: 2519394.5000 - val_mae: 1309.5715\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 770360.2500 - mae: 661.3063 - val_loss: 2970791.5000 - val_mae: 1477.6360\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 615735.3750 - mae: 594.2449 - val_loss: 2786300.5000 - val_mae: 1442.1471\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 677226.8125 - mae: 624.3176 - val_loss: 2350173.2500 - val_mae: 1290.2379\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 2s 107ms/step - loss: 549637.7500 - mae: 559.8754 - val_loss: 2389579.5000 - val_mae: 1236.6482\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 564182.9375 - mae: 570.5411 - val_loss: 2706879.0000 - val_mae: 1390.3756\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 539516.1250 - mae: 547.3329 - val_loss: 3279409.2500 - val_mae: 1576.8541\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 2s 108ms/step - loss: 641196.5625 - mae: 609.8027 - val_loss: 2453615.7500 - val_mae: 1302.0735\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 468444.0312 - mae: 521.1862 - val_loss: 2328873.7500 - val_mae: 1275.1587\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 456754.4062 - mae: 516.4457 - val_loss: 3012744.7500 - val_mae: 1472.4175\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 2s 108ms/step - loss: 960182.8125 - mae: 764.8900 - val_loss: 2656263.0000 - val_mae: 1339.7603\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 768094.5625 - mae: 686.0614 - val_loss: 2471338.5000 - val_mae: 1309.2262\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 645699.9375 - mae: 623.6158 - val_loss: 3418332.0000 - val_mae: 1573.4316\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 666445.9375 - mae: 620.0749 - val_loss: 2733501.2500 - val_mae: 1332.3815\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 604308.0625 - mae: 588.5277 - val_loss: 3236204.0000 - val_mae: 1485.5520\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 524680.0000 - mae: 552.4695 - val_loss: 2581070.2500 - val_mae: 1350.1620\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 510902.3438 - mae: 523.6063 - val_loss: 2858503.2500 - val_mae: 1397.9215\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 505886.1562 - mae: 543.1376 - val_loss: 2833057.0000 - val_mae: 1412.3451\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 449994.5938 - mae: 499.7490 - val_loss: 2660301.2500 - val_mae: 1408.4244\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 455849.0312 - mae: 496.6187 - val_loss: 2332217.0000 - val_mae: 1263.7593\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 2s 107ms/step - loss: 495238.2188 - mae: 527.0842 - val_loss: 2504373.0000 - val_mae: 1337.5349\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 412050.0938 - mae: 490.1831 - val_loss: 2735154.7500 - val_mae: 1403.2821\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 2s 107ms/step - loss: 379947.7500 - mae: 459.8454 - val_loss: 2486879.2500 - val_mae: 1311.0564\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 388302.4375 - mae: 453.2898 - val_loss: 2388741.0000 - val_mae: 1247.6844\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 475065.0938 - mae: 533.6064 - val_loss: 2468889.7500 - val_mae: 1320.5148\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 403976.3125 - mae: 486.4318 - val_loss: 2887045.0000 - val_mae: 1418.1716\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 2s 107ms/step - loss: 380401.8438 - mae: 452.0333 - val_loss: 2286557.2500 - val_mae: 1233.1191\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 421463.6250 - mae: 476.8016 - val_loss: 2890664.0000 - val_mae: 1419.3391\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 396468.0312 - mae: 473.0238 - val_loss: 2733900.2500 - val_mae: 1362.2606\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 2s 108ms/step - loss: 403374.7500 - mae: 476.3295 - val_loss: 2495844.0000 - val_mae: 1272.5637\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 561696.3125 - mae: 570.1234 - val_loss: 2245891.7500 - val_mae: 1235.4967\n",
            "\n",
            "\n",
            "History und Logfiles:\n",
            "#####################\n",
            "\n",
            "- Final trainiertes Modell wurde gespeichert\n",
            "- Plots des Modells wurden gespeichert\n",
            "- Evaluieren der einzelnen Bilder des Trainingsplit per predict wurde durchgeführt\n",
            "- Evaluieren der einzelnen Bilder des Validationsplit per predict wurde durchgeführt\n",
            "- Allgemeines evaluieren des Modells wurde durchgeführt\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "############################################################################################\n",
            "#                                                                                          #\n",
            "#                                  Training 2                                             #\n",
            "#                                                                                          #\n",
            "############################################################################################\n",
            "\n",
            "Parameter:\n",
            "##########\n",
            "\n",
            "Modellnummer: 1\n",
            "Normalisierung: 0\n",
            "Standardisierung: 0\n",
            "Preprocessing: 0\n",
            "Bilder mit Sticker (rot, Aruco, etc.): 0\n",
            "Auflösung Breite: 400\n",
            "Auflösung Höhe: 300\n",
            "Synthetisch - gespiegelt: 0\n",
            "Synthetisch - rotiert: 0\n",
            "Synthetisch - Rauschen: 0\n",
            "Synthetisch - Helligkeit: 0\n",
            "Synthetisch - Schärfe: 0\n",
            "\n",
            "\n",
            "Einlesen der Daten:\n",
            "###################\n",
            "\n",
            "Anzahl aller verwendeten Wände/Szenen: 112\n",
            "Anzahl der Wände/Szenen für das Trainingset: 89\n",
            "Anzahl der Wände/Szenen für das Validationset: 23\n",
            "\n",
            "Anzahl aller verwendeter Bilder: 421\n",
            "\n",
            "Traingset:\n",
            "Anzahl der im Array x_train_material gespeicherten Bilder: 339\n",
            "Anzahl der im Array y_train_material gespeicherten Labels: 339\n",
            "y_train_material Min: 1688\n",
            "y_train_material Max: 12008\n",
            "y_train_material Mean: 7397\n",
            "\n",
            "Validationset:\n",
            "Anzahl der im Array x_val_material gespeicherten Bilder: 82\n",
            "Anzahl der im Array y_val_material gespeicherten Labels: 82\n",
            "y_val_material Min: 2069\n",
            "y_val_material Max: 14992\n",
            "y_val_material Mean: 6518\n",
            "\n",
            "\n",
            "Definieren des Modells:\n",
            "#######################\n",
            "\n",
            "Modell 1 gewählt\n",
            "\n",
            "\n",
            "Printen des Modells:\n",
            "####################\n",
            "\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 298, 398, 128)     3584      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 148, 198, 128)    0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 146, 196, 128)     147584    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 72, 97, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 70, 95, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 34, 47, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 32, 45, 512)       1180160   \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 15, 22, 512)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 168960)            0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 168960)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               86508032  \n",
            "                                                                 \n",
            " material (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 88,135,041\n",
            "Trainable params: 88,135,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "\n",
            "Trainieren des Modells:\n",
            "#######################\n",
            "\n",
            "Epoch 1/100\n",
            "11/11 [==============================] - 9s 844ms/step - loss: 84567264.0000 - mae: 7212.7759 - val_loss: 21247602.0000 - val_mae: 3215.0850\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 5s 444ms/step - loss: 15748871.0000 - mae: 3179.3584 - val_loss: 12916277.0000 - val_mae: 2429.1904\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 5s 445ms/step - loss: 9623726.0000 - mae: 2597.9131 - val_loss: 11956897.0000 - val_mae: 2438.8992\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 5s 450ms/step - loss: 7787210.5000 - mae: 2361.9971 - val_loss: 12761129.0000 - val_mae: 2931.5430\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 5s 454ms/step - loss: 7580848.0000 - mae: 2286.5742 - val_loss: 11796504.0000 - val_mae: 2677.1860\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 5s 451ms/step - loss: 7332877.5000 - mae: 2228.8940 - val_loss: 11235462.0000 - val_mae: 2478.5586\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 5s 448ms/step - loss: 6392287.5000 - mae: 2096.2693 - val_loss: 11035187.0000 - val_mae: 2451.4116\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 5s 446ms/step - loss: 6049394.5000 - mae: 2017.4855 - val_loss: 10726322.0000 - val_mae: 2501.8799\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 5s 445ms/step - loss: 4763183.0000 - mae: 1769.8066 - val_loss: 9150405.0000 - val_mae: 2215.9482\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 3773202.0000 - mae: 1578.4338 - val_loss: 9156204.0000 - val_mae: 2084.5049\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 5s 440ms/step - loss: 3509848.0000 - mae: 1537.0540 - val_loss: 10345922.0000 - val_mae: 2169.1177\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 5s 439ms/step - loss: 2805566.5000 - mae: 1352.8041 - val_loss: 8882043.0000 - val_mae: 2186.7114\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 5s 438ms/step - loss: 2672147.7500 - mae: 1322.3773 - val_loss: 8725271.0000 - val_mae: 2029.7351\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 5s 440ms/step - loss: 2406612.7500 - mae: 1254.1879 - val_loss: 8597971.0000 - val_mae: 2093.1367\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 5s 439ms/step - loss: 2182724.2500 - mae: 1169.1407 - val_loss: 7899578.5000 - val_mae: 1984.2493\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 5s 440ms/step - loss: 1776628.5000 - mae: 1031.2780 - val_loss: 8143856.5000 - val_mae: 1914.6261\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 5s 438ms/step - loss: 2013510.0000 - mae: 1113.6169 - val_loss: 7809636.0000 - val_mae: 1977.2020\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 5s 440ms/step - loss: 1629720.3750 - mae: 991.7866 - val_loss: 8281497.0000 - val_mae: 1939.9216\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 5s 440ms/step - loss: 1537795.2500 - mae: 947.1794 - val_loss: 8057172.5000 - val_mae: 1936.3129\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 5s 441ms/step - loss: 1785847.1250 - mae: 1062.0291 - val_loss: 7530226.0000 - val_mae: 1929.8032\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 5s 441ms/step - loss: 1478303.8750 - mae: 948.3443 - val_loss: 7658963.5000 - val_mae: 1897.9169\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 1309773.5000 - mae: 854.7189 - val_loss: 7081579.5000 - val_mae: 1886.7159\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 1408800.2500 - mae: 929.4105 - val_loss: 8766369.0000 - val_mae: 2171.0142\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 5s 441ms/step - loss: 1404114.0000 - mae: 931.7699 - val_loss: 6688050.0000 - val_mae: 1960.5319\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 1902524.2500 - mae: 1128.9685 - val_loss: 7037573.5000 - val_mae: 1905.2302\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 1493007.1250 - mae: 977.6496 - val_loss: 7143333.5000 - val_mae: 1832.4552\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 5s 444ms/step - loss: 1167439.3750 - mae: 829.2750 - val_loss: 6840404.5000 - val_mae: 1829.8348\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 1019012.4375 - mae: 762.5592 - val_loss: 6697508.0000 - val_mae: 1814.1392\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 951863.8750 - mae: 733.3049 - val_loss: 8068221.0000 - val_mae: 1991.6331\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 5s 446ms/step - loss: 919805.4375 - mae: 731.1273 - val_loss: 6978027.0000 - val_mae: 1865.5792\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 5s 441ms/step - loss: 796985.3750 - mae: 663.0010 - val_loss: 6295976.0000 - val_mae: 1757.8561\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 815701.5000 - mae: 695.8456 - val_loss: 6507139.5000 - val_mae: 1748.0835\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 5s 441ms/step - loss: 652842.1250 - mae: 574.0655 - val_loss: 6808415.0000 - val_mae: 1757.9169\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 5s 440ms/step - loss: 655984.6250 - mae: 617.9215 - val_loss: 5529348.5000 - val_mae: 1685.2268\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 5s 440ms/step - loss: 676118.7500 - mae: 623.1370 - val_loss: 6094595.0000 - val_mae: 1722.7197\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 707039.4375 - mae: 615.2856 - val_loss: 6359792.0000 - val_mae: 1728.0513\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 5s 441ms/step - loss: 619408.6875 - mae: 570.2737 - val_loss: 6636719.0000 - val_mae: 1736.3723\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 693702.3125 - mae: 616.3619 - val_loss: 5740971.5000 - val_mae: 1680.5583\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 540158.8750 - mae: 556.7628 - val_loss: 6059779.5000 - val_mae: 1793.0374\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 622516.3125 - mae: 592.3679 - val_loss: 5923787.0000 - val_mae: 1727.2524\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 503358.1250 - mae: 516.6254 - val_loss: 5794213.5000 - val_mae: 1700.4979\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 487621.0000 - mae: 524.4740 - val_loss: 5850217.0000 - val_mae: 1699.9861\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 5s 444ms/step - loss: 436675.5000 - mae: 517.3437 - val_loss: 6057418.5000 - val_mae: 1712.9486\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 456976.0000 - mae: 509.4713 - val_loss: 5187741.0000 - val_mae: 1625.1387\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 440468.8750 - mae: 508.4104 - val_loss: 6560411.5000 - val_mae: 1745.9099\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 5s 444ms/step - loss: 513558.5938 - mae: 537.6102 - val_loss: 6464943.0000 - val_mae: 1784.6426\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 5s 444ms/step - loss: 423708.1875 - mae: 482.0428 - val_loss: 5740142.0000 - val_mae: 1785.0835\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 416915.7812 - mae: 482.9846 - val_loss: 5773489.0000 - val_mae: 1710.7606\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 435683.5000 - mae: 491.1419 - val_loss: 5501288.0000 - val_mae: 1684.5472\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 380395.7500 - mae: 459.7385 - val_loss: 6536385.0000 - val_mae: 1783.2927\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 345339.5938 - mae: 426.3071 - val_loss: 6403439.0000 - val_mae: 1735.6549\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 376347.9062 - mae: 459.1660 - val_loss: 5471528.0000 - val_mae: 1664.6226\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 331407.6562 - mae: 434.3260 - val_loss: 5403649.0000 - val_mae: 1667.3716\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 348613.2500 - mae: 442.7934 - val_loss: 6021796.5000 - val_mae: 1714.4697\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 371218.6562 - mae: 446.9604 - val_loss: 5401450.5000 - val_mae: 1656.0184\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 328820.9688 - mae: 422.0241 - val_loss: 6091208.0000 - val_mae: 1689.9386\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 5s 448ms/step - loss: 341624.1875 - mae: 437.1155 - val_loss: 5675759.0000 - val_mae: 1692.4985\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 5s 444ms/step - loss: 435808.7188 - mae: 486.5740 - val_loss: 6389328.5000 - val_mae: 1732.4001\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 389390.1250 - mae: 486.9669 - val_loss: 5519716.5000 - val_mae: 1693.1738\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 434218.4688 - mae: 506.0520 - val_loss: 5828652.5000 - val_mae: 1730.6348\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 338231.8438 - mae: 444.7892 - val_loss: 5480806.0000 - val_mae: 1668.5115\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 5s 463ms/step - loss: 373656.4688 - mae: 474.1192 - val_loss: 5590807.5000 - val_mae: 1703.3127\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 314670.2812 - mae: 422.5759 - val_loss: 5730390.0000 - val_mae: 1681.3019\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 342068.3125 - mae: 439.7585 - val_loss: 6839211.5000 - val_mae: 1929.2147\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 5s 444ms/step - loss: 448467.4062 - mae: 509.9097 - val_loss: 5412594.0000 - val_mae: 1662.2452\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 375981.9062 - mae: 475.3910 - val_loss: 5612371.5000 - val_mae: 1659.7046\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 471463.3750 - mae: 530.2526 - val_loss: 4406629.0000 - val_mae: 1512.6910\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 347958.6875 - mae: 441.3067 - val_loss: 5681777.5000 - val_mae: 1601.9821\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 337939.0938 - mae: 421.1299 - val_loss: 5907782.0000 - val_mae: 1696.2268\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 5s 444ms/step - loss: 297325.4375 - mae: 395.4700 - val_loss: 5853434.0000 - val_mae: 1706.9321\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 242204.0781 - mae: 389.0799 - val_loss: 5880358.0000 - val_mae: 1686.3424\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 282302.5000 - mae: 387.6083 - val_loss: 5759304.5000 - val_mae: 1685.8420\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 252647.5312 - mae: 384.7366 - val_loss: 5561340.0000 - val_mae: 1675.1012\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 301181.7500 - mae: 411.8563 - val_loss: 5723708.0000 - val_mae: 1683.7112\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 275769.6562 - mae: 388.9357 - val_loss: 5449256.0000 - val_mae: 1659.9086\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 5s 444ms/step - loss: 249619.3281 - mae: 369.7195 - val_loss: 5903858.5000 - val_mae: 1708.8539\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 264083.5000 - mae: 387.0585 - val_loss: 6292775.5000 - val_mae: 1818.8064\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 235249.9844 - mae: 365.7842 - val_loss: 5922821.5000 - val_mae: 1699.1118\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 5s 441ms/step - loss: 243441.9531 - mae: 368.8773 - val_loss: 5881365.0000 - val_mae: 1688.2380\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 185510.3281 - mae: 328.5474 - val_loss: 5744166.5000 - val_mae: 1667.7775\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 219526.7500 - mae: 349.7697 - val_loss: 5337324.5000 - val_mae: 1635.0360\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 289933.8125 - mae: 412.6497 - val_loss: 5694202.0000 - val_mae: 1687.6522\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 5s 441ms/step - loss: 288474.1562 - mae: 430.8062 - val_loss: 5419316.0000 - val_mae: 1656.5153\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 5s 441ms/step - loss: 195799.9531 - mae: 338.6580 - val_loss: 5823930.0000 - val_mae: 1696.1688\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 309404.7500 - mae: 439.6022 - val_loss: 6121705.5000 - val_mae: 1713.6570\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 338212.5938 - mae: 453.2345 - val_loss: 5592164.5000 - val_mae: 1680.4043\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 369297.1562 - mae: 472.6491 - val_loss: 7013705.5000 - val_mae: 1810.0330\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 5s 442ms/step - loss: 308805.2500 - mae: 409.8414 - val_loss: 5753704.0000 - val_mae: 1702.8435\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 5s 444ms/step - loss: 291994.5625 - mae: 418.9711 - val_loss: 5666710.0000 - val_mae: 1653.0962\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 268029.0625 - mae: 389.7267 - val_loss: 5498379.5000 - val_mae: 1654.2194\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 207836.5469 - mae: 339.3600 - val_loss: 6346875.5000 - val_mae: 1761.8904\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 185789.2656 - mae: 334.2061 - val_loss: 5977735.0000 - val_mae: 1702.3992\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 5s 444ms/step - loss: 173583.3438 - mae: 310.4108 - val_loss: 6054406.0000 - val_mae: 1726.0706\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 223444.2031 - mae: 365.3184 - val_loss: 5930849.0000 - val_mae: 1751.6913\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 5s 466ms/step - loss: 299822.2812 - mae: 418.9325 - val_loss: 5505951.0000 - val_mae: 1642.8020\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 5s 441ms/step - loss: 234074.1406 - mae: 375.0254 - val_loss: 5435048.0000 - val_mae: 1632.6353\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 5s 443ms/step - loss: 228192.8281 - mae: 360.0837 - val_loss: 6041556.5000 - val_mae: 1679.5923\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 5s 444ms/step - loss: 240400.9688 - mae: 367.0735 - val_loss: 5474986.0000 - val_mae: 1665.0879\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 5s 444ms/step - loss: 218945.9062 - mae: 351.8780 - val_loss: 6915376.5000 - val_mae: 1767.8882\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 5s 466ms/step - loss: 202637.4531 - mae: 336.4344 - val_loss: 5713974.5000 - val_mae: 1709.5099\n",
            "\n",
            "\n",
            "History und Logfiles:\n",
            "#####################\n",
            "\n",
            "- Final trainiertes Modell wurde gespeichert\n",
            "- Plots des Modells wurden gespeichert\n",
            "- Evaluieren der einzelnen Bilder des Trainingsplit per predict wurde durchgeführt\n",
            "- Evaluieren der einzelnen Bilder des Validationsplit per predict wurde durchgeführt\n",
            "- Allgemeines evaluieren des Modells wurde durchgeführt\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training durchgeführt\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "##################################################################################\n",
        "# Start Training des Modells (CSV)\n",
        "##################################################################################\n",
        "\n",
        "########################################################################\n",
        "# Hauptverzeichnisse festlegen (Google Colab)\n",
        "########################################################################\n",
        "# Lädt Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "###############################################\n",
        "# Quellpfade zum Einlesen der Bilder und Labels\n",
        "###############################################\n",
        "srcpath_images = \"/content/drive/My Drive/Bilddaten\"\n",
        "srcpath_label_infos = \"/content/drive/My Drive/Wand_Label_Infos/\"\n",
        "# Wie heißt die CSV Datei in der die Labelinfos gespeichert sind\n",
        "csv_name = \"Wand_Label_Info8.csv\"\n",
        "# Spalte in der CSV Datei in der die Labelinfos gespeichert sind. \n",
        "# Achtung counter beginnt mit 0. Für die mitgelieferte Wand_Label_Info8.csv \n",
        "# befinden sich die Label für Fugendeckstreifen in Spalte 19 und für\n",
        "# Spachtelmasse an Stelle 23\n",
        "csv_spalte_labelinfo = 23\n",
        "\n",
        "###############################################\n",
        "# Gibt den Zielpfad für Infos des Trainings an\n",
        "###############################################\n",
        "destpath_dir = \"/content/drive/My Drive/Training/\"\n",
        "\n",
        "##################################################\n",
        "# Gibt den Pfad für die Evaluation an\n",
        "##################################################\n",
        "# Pfad zur Eingabe-Datei\n",
        "evalpath_input = \"/content/drive/My Drive/Training/Evaluation_Input.csv\"\n",
        "# Pfad zur Ausgabe-Datei an welche die Ergebnisse angehängt werden sollen\n",
        "evalpath_output = \"/content/drive/My Drive/Training/Evaluation_Output.csv\"\n",
        "\n",
        "\n",
        "##################################################################################\n",
        "# Evaluation_Input_CSV in Array einlesen\n",
        "##################################################################################\n",
        "with open(evalpath_input, encoding=\"utf-8-sig\") as evaluation_input_file:\n",
        "    evaluation_input = np.loadtxt(evaluation_input_file, delimiter=\";\", skiprows=1, dtype=\"int\")\n",
        "print(evaluation_input)\n",
        "\n",
        "\n",
        "i = 0\n",
        "while i < len(evaluation_input):\n",
        "\n",
        "    model_number = evaluation_input[i][0]\n",
        "    # Gibt die Anzahl der Trainingsepochen an\n",
        "    epochs_train = 100\n",
        "    # Nummer des Trainings\n",
        "    # Achtung! Nummer des Trainings nicht wiederverwenden\n",
        "    training_number = i+1\n",
        "    # In welchem Verhältnis sollen die Daten in Train-/Validationssplit\n",
        "    # aufgeteilt werden?\n",
        "    faktorTrainSplit = 0.8\n",
        "\n",
        "    images_with_sticker = evaluation_input[i][4]\n",
        "    # Sollen Bilder welche mit DSLR erstellt wurden verwendet werden?\n",
        "    images_taken_with_DSLR = 0\n",
        "    # Sollen Bilder welche mit dem Smartphone erstellt wurden verwendet werden?\n",
        "    images_taken_with_Smartphone = 1\n",
        "    # Sollen Querformat-Bilder verwendet werden?\n",
        "    images_taken_format_landscape = 1\n",
        "    # Sollen Hochformat-Bilder verwendet werden?\n",
        "    images_taken_format_portrait = 0\n",
        "\n",
        "    # Welche Synthetischen Bilder sollen verwendet werden?\n",
        "    synthetic_images_mirror = evaluation_input[i][7]\n",
        "    synthetic_images_rotation = evaluation_input[i][8]\n",
        "    synthetic_images_noise = evaluation_input[i][9]\n",
        "    synthetic_images_brightness = evaluation_input[i][10]\n",
        "    synthetic_images_sharpness = evaluation_input[i][11]\n",
        "\n",
        "    # Sollen die verwendeten Bilder zur Kontrolle in Dateiverzeichnisse geschrieben werden?\n",
        "    saving_images_to_dir = 0\n",
        "    # Soll das Modell in Verzeichnisse geschrieben werden?\n",
        "    saving_model_to_dir = 1\n",
        "    # Sollen die Bilder Normalisiert werden?\n",
        "    normalizing_images = evaluation_input[i][1]\n",
        "    # Sollen die Bilder Standardisiert werden?\n",
        "    standardizing_images = evaluation_input[i][2]\n",
        "    # Soll Preprocessing genutzt werden? Dabei werden die Bilder in s/w\n",
        "    # konvertiert und mit einem Canny Filter die Kanten hervorgehoben\n",
        "    preprocesing_images = evaluation_input[i][3]\n",
        "\n",
        "    # Soll die Auflösung der Bilder im Vorfeld angepasst werden?\n",
        "    resizing_images = 1\n",
        "    # Werte für die Resize Funktion\n",
        "    # Zukünftige Maße für Querformat festlegen. Achtung Maße müssen zu Modell passen.\n",
        "    widthquer = evaluation_input[i][5]\n",
        "    heightquer = evaluation_input[i][6]\n",
        "    # Zukünftige Maße für Hochformat festlegen. Achtung Maße müssen zu Modell passen.\n",
        "    widthhoch = 300\n",
        "    heighthoch = 400\n",
        "\n",
        "    doTrainingwithParameters(srcpath_images, srcpath_label_infos, csv_name, csv_spalte_labelinfo, destpath_dir, evalpath_output, model_number, \n",
        "                        epochs_train, training_number, images_with_sticker, images_taken_with_DSLR, images_taken_with_Smartphone, \n",
        "                        images_taken_format_landscape, images_taken_format_portrait, synthetic_images_mirror, \n",
        "                        synthetic_images_rotation, synthetic_images_noise, synthetic_images_brightness, synthetic_images_sharpness, \n",
        "                        saving_images_to_dir, saving_model_to_dir, normalizing_images, standardizing_images, preprocesing_images, resizing_images, widthquer, heightquer, faktorTrainSplit)\n",
        "    i += 1\n",
        "print()\n",
        "print(\"Training durchgeführt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ke4Zi8wgcF7R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwZm_sZAc6lU"
      },
      "source": [
        "Mit dieser Zelle wird ein einzelnes Training gestartet. Einzelne Trainingsparamter können in der Zelle definiert werden. Der Code ist entsprechend kommentiert. Nach dem Einlesen der Parameter wird die Methode doTrainingwithParameters aufgerufen und ein Training durchgeführt. Nach dem Training werden Trainingsergebnisse und -paramter an die Evaluation_Output.csv angehängt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls3R4-_wcH1m",
        "outputId": "e8be5ce2-18ba-42e8-e3ac-48786acc76a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "############################################################################################\n",
            "#                                                                                          #\n",
            "#                                  Training 1                                             #\n",
            "#                                                                                          #\n",
            "############################################################################################\n",
            "\n",
            "Parameter:\n",
            "##########\n",
            "\n",
            "Modellnummer: 1\n",
            "Normalisierung: 0\n",
            "Standardisierung: 0\n",
            "Preprocessing: 0\n",
            "Bilder mit Sticker (rot, Aruco, etc.): 0\n",
            "Auflösung Breite: 400\n",
            "Auflösung Höhe: 300\n",
            "Synthetisch - gespiegelt: 1\n",
            "Synthetisch - rotiert: 1\n",
            "Synthetisch - Rauschen: 1\n",
            "Synthetisch - Helligkeit: 1\n",
            "Synthetisch - Schärfe: 1\n",
            "\n",
            "\n",
            "Einlesen der Daten:\n",
            "###################\n",
            "\n",
            "Anzahl aller verwendeten Wände/Szenen: 112\n",
            "Anzahl der Wände/Szenen für das Trainingset: 89\n",
            "Anzahl der Wände/Szenen für das Validationset: 23\n"
          ]
        }
      ],
      "source": [
        "##################################################################################\n",
        "# Start Training des Modells (Einzeln)\n",
        "##################################################################################\n",
        "\n",
        "########################################################################\n",
        "# Hauptverzeichnisse festlegen (Google Colab)\n",
        "########################################################################\n",
        "# Lädt Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "###############################################\n",
        "# Quellpfade zum Einlesen der Bilder und Labels\n",
        "###############################################\n",
        "srcpath_images = \"/content/drive/My Drive/Bilddaten_mitSynth/\"\n",
        "srcpath_label_infos = \"/content/drive/My Drive/Wand_Label_Infos/\"\n",
        "# Wie heißt die CSV Datei in der die Labelinfos gespeichert sind\n",
        "csv_name = \"Wand_Label_Info8.csv\"\n",
        "# Spalte in der CSV Datei in der die Labelinfos gespeichert sind. \n",
        "# Achtung counter beginnt mit 0. Für die mitgelieferte Wand_Label_Info8.csv \n",
        "# befinden sich die Label für Fugendeckstreifen in Spalte 19 und für\n",
        "# Spachtelmasse an Stelle 23\n",
        "csv_spalte_labelinfo = 23\n",
        "\n",
        "###############################################\n",
        "# Gibt den Zielpfad für Infos des Trainings an\n",
        "###############################################\n",
        "destpath_dir = \"/content/drive/My Drive/Training/\"\n",
        "\n",
        "##################################################\n",
        "# Gibt den Pfad für die Evaluation an\n",
        "##################################################\n",
        "# Pfad zur Ausgabe-Datei an welche die Ergebnisse angehängt werden sollen\n",
        "evalpath_output = \"/content/drive/My Drive/Training/Evaluation_Output.csv\"\n",
        "\n",
        "\n",
        "\n",
        "model_number = 1\n",
        "# Gibt die Anzahl der Trainingsepochen an\n",
        "epochs_train = 100\n",
        "# Nummer des Trainings\n",
        "# Achtung! Nummer des Trainings nicht wiederverwenden\n",
        "training_number = 1\n",
        "# In welchem Verhältnis sollen die Daten in Train-/Validationssplit\n",
        "# aufgeteilt werden?\n",
        "faktorTrainSplit = 0.8\n",
        "\n",
        "images_with_sticker = 0\n",
        "# Sollen Bilder welche mit DSLR erstellt wurden verwendet werden?\n",
        "images_taken_with_DSLR = 0\n",
        "# Sollen Bilder welche mit dem Smartphone erstellt wurden verwendet werden?\n",
        "images_taken_with_Smartphone = 1\n",
        "# Sollen Querformat-Bilder verwendet werden?\n",
        "images_taken_format_landscape = 1\n",
        "# Sollen Hochformat-Bilder verwendet werden?\n",
        "images_taken_format_portrait = 0\n",
        "\n",
        "# Welche Synthetischen Bilder sollen verwendet werden?\n",
        "synthetic_images_mirror = 1\n",
        "synthetic_images_rotation = 1\n",
        "synthetic_images_noise = 1\n",
        "synthetic_images_brightness = 1\n",
        "synthetic_images_sharpness = 1\n",
        "\n",
        "# Sollen die verwendeten Bilder zur Kontrolle in Dateiverzeichnisse geschrieben werden?\n",
        "saving_images_to_dir = 1\n",
        "# Soll das Modell in Verzeichnisse geschrieben werden?\n",
        "saving_model_to_dir = 1\n",
        "# Sollen die Bilder Normalisiert werden?\n",
        "normalizing_images = 0\n",
        "# Sollen die Bilder Standardisiert werden?\n",
        "standardizing_images = 0\n",
        "# Soll Preprocessing genutzt werden? Dabei werden die Bilder in s/w\n",
        "# konvertiert und mit einem Canny Filter die Kanten hervorgehoben\n",
        "preprocesing_images = 0\n",
        "\n",
        "# Soll die Auflösung der Bilder im Vorfeld angepasst werden?\n",
        "resizing_images = 1\n",
        "# Werte für die Resize Funktion\n",
        "# Zukünftige Maße für Querformat festlegen. Achtung Maße müssen zu Modell passen.\n",
        "widthquer = 400\n",
        "heightquer = 300\n",
        "# Zukünftige Maße für Hochformat festlegen. Achtung Maße müssen zu Modell passen.\n",
        "widthhoch = 300\n",
        "heighthoch = 400\n",
        "\n",
        "doTrainingwithParameters(srcpath_images, srcpath_label_infos, csv_name, csv_spalte_labelinfo, destpath_dir, evalpath_output, model_number, \n",
        "                    epochs_train, training_number, images_with_sticker, images_taken_with_DSLR, images_taken_with_Smartphone, \n",
        "                    images_taken_format_landscape, images_taken_format_portrait, synthetic_images_mirror, \n",
        "                    synthetic_images_rotation, synthetic_images_noise, synthetic_images_brightness, synthetic_images_sharpness, \n",
        "                    saving_images_to_dir, saving_model_to_dir, normalizing_images, standardizing_images, preprocesing_images, resizing_images, widthquer, heightquer, faktorTrainSplit)\n",
        "\n",
        "\n",
        "print()\n",
        "print(\"Training durchgeführt\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "132c0e36e591f80fe67535a1b6269656d4a4ef8a082a815d73a2fb1c88f7a1fb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
